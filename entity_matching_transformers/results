[1;33mStart dirty_amazon_itunes xlnet [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_amazon_itunes
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=xlnet-base-cased
argument: model_type=xlnet
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_amazon_itunes
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "n_token": -1,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 5,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "torchscript": false,
  "untie_r": true,
  "vocab_size": 32000
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/zye/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
[1;33mStart abt_buy xlnet [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=abt_buy
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=xlnet-base-cased
argument: model_type=xlnet
argument: do_lower_case=True
argument: max_seq_length=265
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/abt_buy
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "n_token": -1,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 5,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "torchscript": false,
  "untie_r": true,
  "vocab_size": 32000
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/zye/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
[1;33mStart dirty_walmart_amazon xlnet [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_walmart_amazon
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=xlnet-base-cased
argument: model_type=xlnet
argument: do_lower_case=True
argument: max_seq_length=150
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_walmart_amazon
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "n_token": -1,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 5,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "torchscript": false,
  "untie_r": true,
  "vocab_size": 32000
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/zye/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
[1;33mStart dirty_dblp_acm xlnet [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_acm
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=xlnet-base-cased
argument: model_type=xlnet
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_acm
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "n_token": -1,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 5,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "torchscript": false,
  "untie_r": true,
  "vocab_size": 32000
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/zye/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
[1;33mStart dirty_dblp_scholar xlnet [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_scholar
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=xlnet-base-cased
argument: model_type=xlnet
argument: do_lower_case=True
argument: max_seq_length=128
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_scholar
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "n_token": -1,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 5,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "torchscript": false,
  "untie_r": true,
  "vocab_size": 32000
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/zye/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
[1;33mStart dirty_amazon_itunes roBERTa [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_amazon_itunes
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=roberta-base
argument: model_type=roberta
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_amazon_itunes
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/zye/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/zye/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
initialized roberta-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 321
*** Example ***
guid: train-0
tokens: <s> ĠIllusion Ġ( Ġfeat Ġ. ĠE ch os mith Ġ) ĠZ edd ĠTrue ĠColors ĠDance Ġ, ĠMusic Ġ, ĠElectronic Ġ2015 ĠIn ters c ope ĠRecords Ġ6 : 30 Ġ$ Ġ1 . 29 Ġ18 - May - 15 </s> </s> ĠTransmission Ġ[ Ġfeat Ġ. ĠX ĠAmb assadors Ġ] ĠDance Ġ& ĠElectronic Ġ$ Ġ1 . 29 Ġ( ĠC Ġ) Ġ2015 ĠIn ters c ope ĠRecords Ġ4 : 02 ĠZ edd ĠTrue ĠColors ĠMay Ġ18 Ġ, Ġ2015 </s>
input_ids: 0 45413 36 11930 479 381 611 366 22357 4839 525 13093 7447 37780 11101 2156 3920 2156 17039 570 96 2696 438 9877 10023 231 35 541 68 112 4 2890 504 12 10004 12 996 2 2 33308 646 11930 479 1577 8387 39876 27779 11101 359 17039 68 112 4 2890 36 230 4839 570 96 2696 438 9877 10023 204 35 4197 525 13093 7447 37780 392 504 2156 570 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: <s> ĠI Ġ' m Ġa ĠMachine Ġ( Ġfeat Ġ. ĠCrystal ĠNicole Ġand ĠTy re se ĠGibson Ġ) ĠDance Ġ, ĠMusic Ġ, ĠRock Ġ, ĠHouse Ġ, ĠElectronic Ġ26 - Aug - 11 ĠDavid ĠGu etta ĠNothing ĠBut Ġthe ĠBeat Ġ$ Ġ1 . 29 Ġ2011 ĠWhat ĠA ĠMusic ĠLtd Ġ, ĠLic ence Ġexclusive ĠPar l ophone ĠMusic ĠFrance Ġ3 : 34 </s> </s> ĠI ĠCan ĠOnly ĠImagine Ġ( Ġfeat Ġ. ĠChris ĠBrown Ġ& ĠLil ĠWayne Ġ) ĠDavid ĠGu etta ĠDance Ġ& ĠElectronic Ġ2015 ĠReal ĠSounds Ġ3 : 29 ĠAugust Ġ26 Ġ, Ġ2011 ĠNothing ĠBut Ġthe ĠBeat Ġ2 . 0 Ġ[ ĠExplicit Ġ] Ġ$ Ġ0 . 99 </s>
input_ids: 0 38 128 119 10 14969 36 11930 479 9793 9185 8 5957 241 1090 9909 4839 11101 2156 3920 2156 2751 2156 446 2156 17039 973 12 20415 12 1225 871 2646 10464 10385 125 5 10841 68 112 4 2890 1466 653 83 3920 2043 2156 24154 4086 5451 2884 462 25999 3920 1470 155 35 3079 2 2 38 2615 4041 15467 36 11930 479 1573 1547 359 14378 6098 4839 871 2646 10464 11101 359 17039 570 2822 24661 155 35 2890 830 973 2156 1466 10385 125 5 10841 132 4 288 646 47972 27779 68 321 4 2831 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: <s> ĠSilver Ġand ĠGold Ġ3 : 33 ĠLittle ĠBig ĠTown ĠPain ĠKiller ĠCountry Ġ, ĠMusic Ġ, ĠHon ky ĠTon k Ġ, ĠContemporary ĠCountry Ġ$ Ġ1 . 29 Ġ2014 ĠLittle ĠBig ĠTown Ġ, ĠLLC ĠUnder Ġexclusive Ġlicense Ġto ĠCapitol ĠRecords ĠNashville Ġ21 - Oct - 14 </s> </s> ĠSilver ĠAnd ĠGold ĠLittle ĠBig ĠTown ĠCountry Ġ( ĠC Ġ) Ġ2014 ĠLittle ĠBig ĠTown ĠLLC ĠUnder Ġexclusive Ġlicense Ġto ĠCapitol ĠRecords ĠNashville Ġ3 : 31 ĠPain ĠKiller Ġ$ Ġ1 . 29 ĠOctober Ġ21 Ġ, Ġ2014 </s>
input_ids: 0 5344 8 2610 155 35 3103 4046 1776 3171 23689 27249 5093 2156 3920 2156 8768 4122 18405 330 2156 28729 5093 68 112 4 2890 777 4046 1776 3171 2156 2291 2096 5451 4385 7 6107 10023 7024 733 12 19144 12 1570 2 2 5344 178 2610 4046 1776 3171 5093 36 230 4839 777 4046 1776 3171 2291 2096 5451 4385 7 6107 10023 7024 155 35 2983 23689 27249 68 112 4 2890 779 733 2156 777 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-3
tokens: <s> ĠDangerous Ġ( Ġfeat Ġ. ĠSam ĠMartin Ġ) Ġ[ ĠRobin ĠSch ulz ĠRemix Ġ] Ġ[ ĠRadio ĠEdit Ġ] ĠDavid ĠGu etta ĠDance Ġ, ĠMusic Ġ, ĠRock Ġ, ĠHouse Ġ, ĠElectronic Ġ, ĠFrench ĠPop Ġ$ Ġ1 . 29 Ġ2014 ĠWhat ĠA ĠMusic ĠLtd . Ġunder Ġexclusive Ġlicense Ġto ĠPar l ophone / War ner ĠMusic ĠFrance Ġ, Ġunder Ġexclusive Ġlicense Ġto ĠAtlantic ĠRecording ĠCorporation Ġfor Ġthe ĠUnited ĠStates Ġ. ĠAll Ġrights Ġreserved Ġ. Ġ24 - Nov - 14 ĠListen Ġ( ĠDeluxe ĠVersion Ġ) Ġ3 : 20 </s> </s> ĠI Ġ' ll ĠKeep ĠLoving Ġyou Ġ( Ġfeat Ġ. ĠBird y Ġ& ĠJay mes ĠYoung Ġ) ĠDavid ĠGu etta ĠListen Ġ( ĠDeluxe Ġ) Ġ$ Ġ1 . 29 Ġ2015 ĠIf ĠMoving ĠYour ĠMine ĠNovember Ġ24 Ġ, Ġ2014 ĠDance Ġ& ĠElectronic Ġ3 : 08 </s>
input_ids: 0 34360 36 11930 479 1960 1896 4839 646 8472 1811 24853 43902 27779 646 4611 39391 27779 871 2646 10464 11101 2156 3920 2156 2751 2156 446 2156 17039 2156 1515 7975 68 112 4 2890 777 653 83 3920 2043 4 223 5451 4385 7 2884 462 25999 73 20096 1396 3920 1470 2156 223 5451 4385 7 5038 34601 2824 13 5 315 532 479 404 659 1875 479 706 12 18187 12 1570 13041 36 35721 35110 4839 155 35 844 2 2 38 128 890 7238 34418 47 36 11930 479 9908 219 359 3309 12579 2880 4839 871 2646 10464 13041 36 35721 4839 68 112 4 2890 570 318 15008 2486 16417 759 706 2156 777 11101 359 17039 155 35 3669 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: <s> ĠTrue ĠColors Ġ( Ġfeat Ġ. ĠNick i ĠMin aj Ġ) ĠWiz ĠKhal ifa ĠHip - Hop / Rap Ġ, ĠMusic Ġ, ĠRap Ġ, ĠEast ĠCoast ĠRap Ġ, ĠHardcore ĠRap Ġ, ĠRock Ġ4 : 15 Ġ19 - Aug - 14 ĠBl acc ĠHollywood Ġ$ Ġ1 . 29 Ġ2014 ĠAtlantic ĠRecording ĠCorporation Ġfor Ġthe ĠUnited ĠStates Ġand ĠWE A ĠInternational ĠInc . Ġfor Ġthe Ġworld Ġoutside Ġof Ġthe ĠUnited ĠStates Ġ. ĠA ĠWarner ĠMusic ĠGroup ĠCompany </s> </s> ĠStill ĠDown Ġ( Ġfeat Ġ. ĠChevy ĠWoods Ġ& ĠTy ĠDoll a Ġ$ Ġign Ġ) Ġ[ ĠExplicit Ġ] Ġ$ Ġ1 . 29 Ġ2014 ĠAtlantic ĠRecording ĠCorporation Ġfor Ġthe ĠUnited ĠStates Ġand ĠWE A ĠInternational ĠInc . Ġfor Ġthe Ġworld Ġoutside Ġof Ġthe ĠUnited ĠStates Ġ. ĠA ĠWarner ĠMusic ĠGroup ĠCompany Ġ4 : 16 ĠAugust Ġ19 Ġ, Ġ2014 ĠWiz ĠKhal ifa ĠBl acc ĠHollywood Ġ[ ĠExplicit Ġ] ĠRap Ġ& ĠHip - Hop </s>
input_ids: 0 7447 37780 36 11930 479 2651 118 3635 1176 4839 32436 14373 15247 20496 12 30158 73 39310 2156 3920 2156 16469 2156 953 2565 16469 2156 46206 16469 2156 2751 204 35 996 753 12 20415 12 1570 2091 7904 3049 68 112 4 2890 777 5038 34601 2824 13 5 315 532 8 10284 250 1016 603 4 13 5 232 751 9 5 315 532 479 83 6123 3920 826 1260 2 2 3180 5818 36 11930 479 22046 5227 359 5957 25678 102 68 29852 4839 646 47972 27779 68 112 4 2890 777 5038 34601 2824 13 5 315 532 8 10284 250 1016 603 4 13 5 232 751 9 5 315 532 479 83 6123 3920 826 1260 204 35 1549 830 753 2156 777 32436 14373 15247 2091 7904 3049 646 47972 27779 16469 359 20496 12 30158 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-138' was too long (tokens_a:95, tokens_b:83). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-253' was too long (tokens_a:102, tokens_b:101). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-275' was too long (tokens_a:74, tokens_b:103). Max_seq_length is 176, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 321
  Batch size = 16
  Max Sequence Length = 180
loaded 321 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 109
*** Example ***
guid: test-0
tokens: <s> ĠElev ator Ġ( Ġfeat Ġ. ĠTim bal and Ġ) ĠFlo ĠR ida ĠMail ĠOn ĠSunday Ġ( ĠDeluxe ĠVersion Ġ) ĠHip - Hop / Rap Ġ, ĠMusic Ġ, ĠDirty ĠSouth Ġ3 : 55 Ġ17 - Mar - 08 Ġ$ Ġ1 . 99 Ġ2008 ĠAtlantic ĠRecording ĠCorporation Ġfor Ġthe ĠUnited ĠStates Ġand ĠWE A ĠInternational ĠInc . Ġfor Ġthe Ġworld Ġoutside Ġof Ġthe ĠUnited ĠStates </s> </s> ĠMoney ĠRight Ġ( Ġfeat Ġ. ĠRick ĠRoss Ġ& ĠBr isco Ġ) Ġ[ ĠExplicit Ġ] ĠRap Ġ& ĠHip - Hop ĠMarch Ġ17 Ġ, Ġ2008 ĠFlo ĠR ida ĠMail ĠOn ĠSunday Ġ[ ĠExplicit Ġ] Ġ$ Ġ1 . 29 Ġ2013 ĠWarner ĠBros . Ġ. ĠRecords ĠInc . Ġ3 : 17 </s>
input_ids: 0 32099 2630 36 11930 479 2668 8667 463 4839 32932 248 4347 6313 374 395 36 35721 35110 4839 20496 12 30158 73 39310 2156 3920 2156 30375 391 155 35 3118 601 12 10169 12 3669 68 112 4 2831 2266 5038 34601 2824 13 5 315 532 8 10284 250 1016 603 4 13 5 232 751 9 5 315 532 2 2 8028 5143 36 11930 479 4434 4012 359 2265 15069 4839 646 47972 27779 16469 359 20496 12 30158 494 601 2156 2266 32932 248 4347 6313 374 395 646 47972 27779 68 112 4 2890 1014 6123 11712 4 479 10023 603 4 155 35 1360 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: <s> ĠThe ĠWood land ĠRealm Ġ( ĠExtended ĠVersion Ġ) ĠHoward ĠShore ĠThe ĠHobbit Ġ: ĠThe ĠDes olation Ġof ĠSm aug Ġ( ĠOriginal ĠMotion ĠPicture ĠSound track Ġ) Ġ[ ĠSpecial ĠEdition Ġ] ĠSound track Ġ, ĠMusic Ġ, ĠSound track Ġ, ĠClassical Ġ, ĠOriginal ĠScore Ġ$ Ġ1 . 29 Ġ5 : 14 Ġ10 - Dec - 13 ĠâĢ ° ĠÃ £ Ã ĳ Ġ2013 ĠWater T ower ĠMusic </s> </s> ĠThe ĠHigh ĠF ells Ġ( ĠExtended ĠVersion Ġ) ĠThe ĠHobbit Ġ: ĠThe ĠDes olation Ġof ĠSm aug Ġ( ĠOriginal ĠMotion ĠPicture ĠSound track Ġ) Ġ[ ĠSpecial ĠEdition Ġ] Ġ$ Ġ1 . 29 Ġ2013 ĠWater T ower ĠMusic Ġ/ ĠWarner ĠBros . Ġ. ĠEntertainment Ġ/ ĠMetro Ġ- ĠGold wyn ĠMayer ĠPictures ĠInc . ĠDecember Ġ10 Ġ, Ġ2013 ĠHoward ĠShore ĠSound tracks Ġ3 : 38 </s>
input_ids: 0 20 3132 1245 38814 36 36358 35110 4839 5218 10291 20 44742 4832 20 4762 35626 9 4966 12361 36 15973 16950 5311 8479 16026 4839 646 3672 12603 27779 8479 16026 2156 3920 2156 8479 16026 2156 39641 2156 15973 14702 68 112 4 2890 195 35 1570 158 12 15953 12 1558 44 7487 952 2469 3849 3602 1014 3201 565 8285 3920 2 2 20 755 274 17150 36 36358 35110 4839 20 44742 4832 20 4762 35626 9 4966 12361 36 15973 16950 5311 8479 16026 4839 646 3672 12603 27779 68 112 4 2890 1014 3201 565 8285 3920 1589 6123 11712 4 479 5528 1589 5768 111 2610 16541 21296 12290 603 4 719 158 2156 1014 5218 10291 8479 36546 155 35 3170 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: <s> ĠExtra ĠExtra ĠCredit ĠWiz ĠKhal ifa ĠFlight ĠSchool Ġ$ Ġ0 . 99 Ġ2009 ĠRost rum ĠRecords Ġ4 : 03 ĠHip - Hop / Rap Ġ, ĠMusic Ġ17 - Apr - 09 </s> </s> ĠExtra ĠExtra ĠCredit Ġ[ ĠExplicit Ġ] ĠWiz ĠKhal ifa Ġ2013 ĠMad ĠDec ent ĠFlight ĠSchool Ġ[ ĠExplicit Ġ] ĠRap Ġ& ĠHip - Hop Ġ$ Ġ0 . 99 Ġ4 : 03 ĠApril Ġ17 Ġ, Ġ2009 </s>
input_ids: 0 18355 18355 3560 32436 14373 15247 13275 835 68 321 4 2831 2338 30610 10904 10023 204 35 3933 20496 12 30158 73 39310 2156 3920 601 12 41872 12 3546 2 2 18355 18355 3560 646 47972 27779 32436 14373 15247 1014 4145 1502 1342 13275 835 646 47972 27779 16469 359 20496 12 30158 68 321 4 2831 204 35 3933 587 601 2156 2338 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: test-3
tokens: <s> ĠToy friend Ġ( Ġfeat Ġ. ĠWyn ter ĠGordon Ġ) Ġ[ ĠContinuous ĠMix ĠVersion Ġ] ĠDavid ĠGu etta Ġ$ Ġ1 . 29 Ġ2010 ĠGum ĠPro d Ġlicence Ġexclusive ĠPar l ophone ĠMusic ĠFrance Ġ21 - Aug - 09 ĠOne ĠLove Ġ( ĠDeluxe ĠVersion Ġ) ĠDance Ġ, ĠMusic Ġ2 : 51 </s> </s> ĠSound ĠOf ĠLet ting ĠGo Ġ( ĠF eat Ġ. ĠChris ĠWillis Ġ) ĠDance Ġ& ĠElectronic ĠAugust Ġ21 Ġ, Ġ2009 ĠDavid ĠGu etta ĠOne ĠLove Ġ( ĠDeluxe ĠVersion Ġ) Ġ$ Ġ1 . 29 Ġ( ĠC Ġ) Ġ2014 ĠSwedish ĠHouse ĠMafia ĠHoldings ĠLtd Ġ( ĠB VI Ġ) Ġunder Ġexclusive Ġlicense Ġto ĠVirgin ĠRecords ĠLtd Ġ3 : 47 </s>
input_ids: 0 18243 18028 36 11930 479 15523 1334 5613 4839 646 37737 16038 35110 27779 871 2646 10464 68 112 4 2890 1824 32778 1698 417 10362 5451 2884 462 25999 3920 1470 733 12 20415 12 3546 509 3437 36 35721 35110 4839 11101 2156 3920 132 35 4708 2 2 8479 1525 2780 2577 2381 36 274 21046 479 1573 16575 4839 11101 359 17039 830 733 2156 2338 871 2646 10464 509 3437 36 35721 35110 4839 68 112 4 2890 36 230 4839 777 9004 446 37516 4357 2043 36 163 15176 4839 223 5451 4385 7 9880 10023 2043 155 35 3706 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: <s> ĠDangerous Ġ( Ġfeat Ġ. ĠSam ĠMartin Ġ) Ġ[ ĠRobin ĠSch ulz ĠRemix Ġ] Ġ[ ĠRadio ĠEdit Ġ] ĠListen Ġ( ĠDeluxe ĠVersion Ġ) ĠDance Ġ, ĠMusic Ġ, ĠRock Ġ, ĠHouse Ġ, ĠElectronic Ġ, ĠFrench ĠPop Ġ2014 ĠWhat ĠA ĠMusic ĠLtd . Ġunder Ġexclusive Ġlicense Ġto ĠPar l ophone / War ner ĠMusic ĠFrance Ġ, Ġunder Ġexclusive Ġlicense Ġto ĠAtlantic ĠRecording ĠCorporation Ġfor Ġthe ĠUnited ĠStates Ġ. ĠAll Ġrights Ġreserved Ġ. Ġ3 : 20 Ġ24 - Nov - 14 ĠDavid ĠGu etta Ġ$ Ġ1 . 29 </s> </s> ĠMissing ĠYou Ġ( ĠF eat Ġ. ĠNovel Ġ; ĠContinuous ĠMix ĠVersion Ġ) ĠDavid ĠGu etta ĠOne ĠLove Ġ( ĠDeluxe ĠVersion Ġ) ĠDance Ġ& ĠElectronic Ġ$ Ġ1 . 29 Ġ( ĠC Ġ) Ġ2014 ĠSwedish ĠHouse ĠMafia ĠHoldings ĠLtd Ġ( ĠB VI Ġ) Ġunder Ġexclusive Ġlicense Ġto ĠVirgin ĠRecords ĠLtd Ġ4 : 59 ĠAugust Ġ21 Ġ, Ġ2009 </s>
input_ids: 0 34360 36 11930 479 1960 1896 4839 646 8472 1811 24853 43902 27779 646 4611 39391 27779 13041 36 35721 35110 4839 11101 2156 3920 2156 2751 2156 446 2156 17039 2156 1515 7975 777 653 83 3920 2043 4 223 5451 4385 7 2884 462 25999 73 20096 1396 3920 1470 2156 223 5451 4385 7 5038 34601 2824 13 5 315 532 479 404 659 1875 479 155 35 844 706 12 18187 12 1570 871 2646 10464 68 112 4 2890 2 2 23632 370 36 274 21046 479 36338 25606 37737 16038 35110 4839 871 2646 10464 509 3437 36 35721 35110 4839 11101 359 17039 68 112 4 2890 36 230 4839 777 9004 446 37516 4357 2043 36 163 15176 4839 223 5451 4385 7 9880 10023 2043 204 35 4156 830 733 2156 2338 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 109
  Batch size = 16
  Max Sequence Length = 180
loaded and initialized evaluation examples 109
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7361767036574227
f1_score: 0.39705882352941174
simple_accuracy: 0.24770642201834864
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        82
           1       0.25      1.00      0.40        27

    accuracy                           0.25       109
   macro avg       0.12      0.50      0.20       109
weighted avg       0.06      0.25      0.10       109

[1;33mStart abt_buy roBERTa [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=abt_buy
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=roberta-base
argument: model_type=roberta
argument: do_lower_case=True
argument: max_seq_length=265
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/abt_buy
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/zye/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/zye/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
initialized roberta-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 5743
*** Example ***
guid: train-0
tokens: <s> Ġl g Ġ24 Ġ' Ġl ds 48 21 ww Ġsemi Ġintegrated Ġbuilt Ġin Ġwhite Ġdish washer Ġl ds 48 21 wh Ġx l Ġtall Ġtub Ġcleans Ġup Ġto Ġ16 Ġplace Ġsettings Ġat Ġonce Ġadjustable Ġupper Ġrack Ġlod ec ibel Ġquiet Ġoperation Ġsense clean Ġwash Ġsystem Ġ4 Ġwash Ġcycles Ġwith Ġ3 Ġspray Ġarms Ġmulti - level Ġwater Ġdirection Ġslim Ġdirect Ġdrive Ġmotor Ġsemi - integ rated Ġelectronic Ġcontrol Ġpanel Ġwhite Ġfinish </s> </s> Ġl g Ġl df 69 20 bb Ġfully Ġintegrated Ġdish washer </s>
input_ids: 0 784 571 706 128 784 11622 3818 2146 33130 4126 6818 1490 11 1104 8847 34475 784 11622 3818 2146 11613 3023 462 6764 17465 30317 62 7 545 317 9629 23 683 29861 2853 20004 35610 3204 31477 5128 2513 1472 28401 10397 467 204 10397 16726 19 155 11782 3701 3228 12 4483 514 2698 11875 2228 1305 4243 4126 12 24894 8358 5175 797 2798 1104 2073 2 2 784 571 784 36807 4563 844 14141 1950 6818 8847 34475 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: <s> Ġspe ck Ġse eth ru Ġclear Ġhard Ġshell Ġcase Ġfor Ġmac book Ġair Ġm b ac lr see Ġthin Ġand Ġsleek Ġprotective Ġcase Ġaccess Ġto Ġall Ġports Ġ2 - piece Ġsnap Ġon Ġclear Ġfinish </s> </s> Ġspe ck Ġproducts Ġse eth ru Ġcase Ġfor Ġapple Ġ13 Ġ' Ġmac book Ġm b 13 - pn k - see - v 2 Ġplastic Ġpink </s>
input_ids: 0 25227 2420 842 4774 2070 699 543 10785 403 13 13418 6298 935 475 428 1043 35265 7048 7174 8 19474 11775 403 899 7 70 9507 132 12 10449 6788 15 699 2073 2 2 25227 2420 785 842 4774 2070 403 13 15162 508 128 13418 6298 475 428 1558 12 35857 330 12 7048 12 705 176 4136 6907 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: <s> Ġden on Ġblu - ray Ġdisc Ġd vd / cd Ġplayer Ġd vd 38 00 bd ci Ġ10 - bit Ġreal ta Ġh qv Ġvideo Ġprocessor Ġ1080 p / 24 fps Ġoutput Ġand Ġmulti - c ad ence Ġdetection Ġh d mi Ġ1 . 3 Ġa Ġoutput Ġwith Ġ36 - bit Ġdeep Ġcolor Ġsupport Ġdual Ġ32 - bit Ġfloating Ġpoint Ġd sp Ġmulti - lay ered Ġconstruction Ġwith Ġdual - lay ered Ġtop Ġshields Ġand Ġtriple - lay ered Ġbottom Ġsuppress Ġvibration Ġhybrid Ġ( Ġs . v . h . Ġ) Ġloader Ġblack Ġfinish </s> </s> Ġden on Ġd vd - 29 30 ci Ġd vd Ġplayer Ġd vd 29 30 ci Ġd vd Ġ+ Ġr w Ġ, Ġd vd - rw Ġ, Ġcd - rw Ġd vd Ġvideo Ġ, Ġd vd Ġaudio Ġ, Ġsac d Ġ, Ġvideo Ġcd Ġ, Ġpicture Ġcd Ġ, Ġj peg Ġ, Ġw ma Ġ, Ġp cm Ġ, Ġh d cd Ġ, Ġmp 3 Ġ, Ġm peg - 1 Ġ, Ġm peg - 2 Ġ, Ġm peg - 4 Ġ, Ġdiv x Ġplayback Ġ1 Ġdisc Ġ( Ġs Ġ) Ġprogressive Ġscan Ġblack </s>
input_ids: 0 3069 261 42034 12 5022 9553 385 40311 73 28690 869 385 40311 3170 612 35470 2520 158 12 5881 588 4349 1368 22638 569 10655 21083 642 73 1978 36151 4195 8 3228 12 438 625 4086 12673 1368 417 5408 112 4 246 10 4195 19 2491 12 5881 1844 3195 323 6594 2107 12 5881 11291 477 385 4182 3228 12 8433 3215 1663 19 6594 12 8433 3215 299 31768 8 6436 12 8433 3215 2576 23192 35911 9284 36 579 4 705 4 298 4 4839 44500 909 2073 2 2 3069 261 385 40311 12 2890 541 2520 385 40311 869 385 40311 2890 541 2520 385 40311 2055 910 605 2156 385 40311 12 43926 2156 45584 12 43926 385 40311 569 2156 385 40311 6086 2156 22636 417 2156 569 45584 2156 2170 45584 2156 1236 41191 2156 885 1916 2156 181 13753 2156 1368 417 28690 2156 44857 246 2156 475 41191 12 134 2156 475 41191 12 176 2156 475 41191 12 306 2156 14445 1178 20083 112 9553 36 579 4839 8212 14194 909 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: <s> Ġpan asonic Ġde ct Ġ6 . 0 Ġexpand able Ġdigital Ġcord less Ġphone Ġwith Ġall - digital Ġanswering Ġsystem Ġk xt g 9 343 t Ġ3 Ġhands ets Ġsystem Ġup Ġto Ġ6 Ġmulti - hands et Ġcapability Ġdigital Ġanswering Ġmachine Ġsystem Ġr inger Ġid Ġcall Ġwaiting Ġcaller Ġid Ġvoic email Ġhold Ġvoice Ġmenu Ġmarker Ġmessage Ġmute Ġclock Ġalarm Ġled Ġlighting Ġnight Ġmode Ġcall Ġblock Ġspeaker phone Ġ11 Ġdays Ġstandby Ġ5 Ġhours Ġtalk Ġtime Ġblack Ġmetallic Ġfinish </s> </s> Ġpan asonic Ġk x - tg 10 32 s Ġdual Ġhandset Ġdigital Ġcord less Ġphone Ġ1 Ġx Ġphone Ġline Ġ( Ġs Ġ) Ġheadset Ġjack Ġsilver </s>
input_ids: 0 5730 38703 263 3894 231 4 288 3003 868 1778 13051 1672 1028 19 70 12 29563 15635 467 449 11483 571 466 31920 90 155 1420 2580 467 62 7 231 3228 12 34055 594 9388 1778 15635 3563 467 910 6082 13561 486 2445 17017 13561 30118 10555 946 2236 5765 17540 1579 33758 6700 8054 669 7526 363 5745 486 1803 5385 17283 365 360 28611 195 722 1067 86 909 24117 2073 2 2 5730 38703 449 1178 12 42698 698 2881 29 6594 17621 1778 13051 1672 1028 112 3023 1028 516 36 579 4839 20084 10267 4334 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: <s> Ġs ony Ġsilver Ġmin id v Ġhandy cam Ġcam c order Ġd cr h c 52 Ġ680 k Ġpixels Ġim ager Ġcar l Ġze iss Ġvar io - t ess ar Ġlens Ġ40 x Ġoptical Ġzoom Ġand Ġ2000 x Ġdigital Ġzoom Ġ2 . 5 Ġ' Ġtouch Ġpanel Ġl cd Ġdisplay Ġsuper Ġstead ys hot Ġimage Ġstabilization Ġsuper Ġnight shot Ġplus Ġtechnology Ġeasy Ġhandy cam Ġbutton Ġf ader Ġeffects Ġmanual Ġfocus Ġmulti - language Ġmenu Ġsilver Ġfinish </s> </s> Ġs ony Ġmin id v Ġhead Ġcleaner Ġd vm 12 c ld Ġhead Ġcleaner </s>
input_ids: 0 579 6119 4334 5251 808 705 14732 16767 11021 438 10337 385 8344 298 438 4429 37326 330 24983 4356 6988 512 462 20025 3006 15747 1020 12 90 3361 271 10373 843 1178 17547 21762 8 3788 1178 1778 21762 132 4 245 128 2842 2798 784 28690 2332 2422 23789 2459 10120 2274 29632 2422 363 10393 2704 806 1365 14732 16767 6148 856 7292 3038 12769 1056 3228 12 19527 5765 4334 2073 2 2 579 6119 5251 808 705 471 16126 385 38486 1092 438 4779 471 16126 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 5743
  Batch size = 16
  Max Sequence Length = 265
loaded 5743 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 1916
*** Example ***
guid: test-0
tokens: <s> Ġs ony Ġpink Ġcyber - shot Ġ7 . 2 Ġmeg apixel Ġdigital Ġcamera Ġd sc w 120 p Ġ7 . 2 Ġmeg apixel Ġ4 x Ġoptical Ġzoom Ġ2 . 5 Ġ' Ġt ft Ġl cd Ġ15 Ġm b Ġinternal Ġmemory Ġface Ġdetection Ġsuper Ġstead ys hot Ġimage Ġstabilization Ġsmile Ġshutter Ġmode Ġsmart Ġzoom Ġpink Ġfinish </s> </s> Ġo lymp us Ġfe - 360 Ġdigital Ġcamera Ġpink Ġ2 265 40 Ġ8 Ġmeg apixel Ġ16 : 9 Ġ3 x Ġoptical Ġzoom Ġ4 x Ġdigital Ġzoom Ġ2 . 5 Ġ' Ġcolor Ġl cd </s>
input_ids: 0 579 6119 6907 5381 12 10393 262 4 176 10721 21424 1778 2280 385 3866 605 10213 642 262 4 176 10721 21424 204 1178 17547 21762 132 4 245 128 326 2543 784 28690 379 475 428 3425 3783 652 12673 2422 23789 2459 10120 2274 29632 6675 27349 5745 2793 21762 6907 2073 2 2 1021 31434 687 10668 12 14586 1778 2280 6907 132 26330 1749 290 10721 21424 545 35 466 155 1178 17547 21762 204 1178 1778 21762 132 4 245 128 3195 784 28690 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: <s> Ġl g Ġ2 . 0 Ġcu Ġ. Ġft . Ġover - the - range Ġwhite Ġmicrowave Ġoven Ġl m vm 20 85 wh Ġwarming Ġlamp Ġglide Ġ& Ġspin Ġsliding Ġtray Ġwith Ġtur nt able Ġsensor Ġcook Ġfeature Ġ300 Ġcf m Ġexhaust Ġsystem Ġhorizontal Ġkey pad Ġelegant Ġhidden Ġvent Ġwide view Ġwindow Ġhal ogen Ġcook top Ġlighting Ġwhite Ġfinish </s> </s> Ġmay tag Ġ2 . 0 Ġcu Ġ. Ġft . Ġover - the - range Ġmicrowave Ġoven </s>
input_ids: 0 784 571 132 4 288 3729 479 16935 4 81 12 627 12 9435 1104 28562 12941 784 119 38486 844 4531 11613 8232 24272 41103 359 6287 15599 27483 19 11342 3999 868 9626 7142 1905 2993 46470 119 19379 467 25490 762 19320 14878 7397 13228 1810 5877 2931 12193 11575 7142 8766 7526 1104 2073 2 2 189 10058 132 4 288 3729 479 16935 4 81 12 627 12 9435 28562 12941 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: <s> Ġpan asonic Ġblack Ġ8 . 5 Ġ' Ġportable Ġd vd Ġplayer Ġd vd ls 83 Ġ8 . 5 Ġ' Ġfree Ġstyle Ġwide Ġscreen Ġl cd Ġdisplay Ġ6 Ġhour Ġbattery Ġmulti Ġformat Ġplayback Ġdual Ġheadphone Ġj acks Ġdiv x Ġplayback Ġcar Ġdc Ġadapter Ġincluded Ġblack Ġfinish </s> </s> Ġto sh iba Ġsd - p 71 s Ġportable Ġd vd Ġplayer Ġto sh iba Ġsd - p 71 s Ġ7 Ġ' Ġportable Ġd vd Ġplayer </s>
input_ids: 0 5730 38703 909 290 4 245 128 15295 385 40311 869 385 40311 6634 6361 290 4 245 128 481 2496 1810 2441 784 28690 2332 231 1946 3822 3228 7390 20083 6594 27671 1236 3400 14445 1178 20083 512 46773 36007 1165 909 2073 2 2 7 1193 15577 46409 12 642 5339 29 15295 385 40311 869 7 1193 15577 46409 12 642 5339 29 262 128 15295 385 40311 869 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: <s> Ġs ony Ġbrav ia Ġtheater Ġblack Ġmicro Ġsystem Ġd avis 50 b Ġ5 . 1 - channel Ġsurround Ġsound Ġgolf Ġball - sized Ġspeakers Ġcompact Ġdesign Ġs - air Ġdigital Ġwireless Ġcapability Ġh d mi Ġconnectivity Ġbrav ia Ġsync Ġdigital Ġcinema Ġsound Ġ( Ġd cs Ġ) Ġtechnology Ġs - master Ġdigital Ġamplifier Ġportable Ġaudio Ġenh ancer Ġblack Ġfinish </s> </s> Ġs ony Ġbrav ia Ġd av - is 50 Ġ/ Ġb Ġhome Ġtheater Ġsystem Ġd vd Ġplayer Ġ, Ġ5 . 1 Ġspeakers Ġ1 Ġdisc Ġ( Ġs Ġ) Ġprogressive Ġscan Ġ450 w Ġr ms Ġd ol by Ġdigital Ġex Ġ, Ġd ol by Ġpro Ġlogic Ġ, Ġd ol by Ġpro Ġlogic Ġii </s>
input_ids: 0 579 6119 35977 493 7364 909 5177 467 385 18045 1096 428 195 4 134 12 27681 21104 2369 3524 1011 12 8407 6864 12549 1521 579 12 2456 1778 6955 9388 1368 417 5408 10335 35977 493 22785 1778 11605 2369 36 385 11365 4839 806 579 12 12974 1778 42521 15295 6086 45378 20126 909 2073 2 2 579 6119 35977 493 385 1469 12 354 1096 1589 741 184 7364 467 385 40311 869 2156 195 4 134 6864 112 9553 36 579 4839 8212 14194 13411 605 910 4339 385 1168 1409 1778 1931 2156 385 1168 1409 1759 14578 2156 385 1168 1409 1759 14578 42661 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: test-4
tokens: <s> Ġpan asonic Ġde ct Ġ6 . 0 Ġexpand able Ġdigital Ġcord less Ġphone Ġwith Ġall - digital Ġanswering Ġsystem Ġk xt g 93 44 t Ġ4 Ġhands ets Ġsystem Ġup Ġto Ġ6 Ġmulti - hands et Ġcapability Ġdigital Ġanswering Ġmachine Ġsystem Ġr inger Ġid Ġcall Ġwaiting Ġcaller Ġid Ġvoic email Ġhold Ġvoice Ġmenu Ġmarker Ġmessage Ġmute Ġclock Ġalarm Ġled Ġlighting Ġnight Ġmode Ġcall Ġblock Ġspeaker phone Ġ11 Ġdays Ġstandby Ġ5 Ġhours Ġtalk Ġtime Ġblack Ġmetallic Ġfinish </s> </s> Ġpan asonic Ġk x - tg 9 342 t Ġcord less Ġphone Ġ1 Ġx Ġphone Ġline Ġ( Ġs Ġ) Ġblack Ġ, Ġmetallic </s>
input_ids: 0 5730 38703 263 3894 231 4 288 3003 868 1778 13051 1672 1028 19 70 12 29563 15635 467 449 11483 571 6478 3305 90 204 1420 2580 467 62 7 231 3228 12 34055 594 9388 1778 15635 3563 467 910 6082 13561 486 2445 17017 13561 30118 10555 946 2236 5765 17540 1579 33758 6700 8054 669 7526 363 5745 486 1803 5385 17283 365 360 28611 195 722 1067 86 909 24117 2073 2 2 5730 38703 449 1178 12 42698 466 33192 90 13051 1672 1028 112 3023 1028 516 36 579 4839 909 2156 24117 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 1916
  Batch size = 16
  Max Sequence Length = 265
loaded and initialized evaluation examples 1916
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7533613666892052
f1_score: 0.1941564561734213
simple_accuracy: 0.10751565762004175
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1710
           1       0.11      1.00      0.19       206

    accuracy                           0.11      1916
   macro avg       0.05      0.50      0.10      1916
weighted avg       0.01      0.11      0.02      1916

[1;33mStart dirty_walmart_amazon roBERTa [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_walmart_amazon
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=roberta-base
argument: model_type=roberta
argument: do_lower_case=True
argument: max_seq_length=150
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_walmart_amazon
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/zye/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/zye/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
initialized roberta-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 6144
*** Example ***
guid: train-0
tokens: <s> Ġelite Ġscreens Ġc in ew h ite Ġcinema 235 Ġseries Ġfixed Ġframe Ġwide Ġscreen Ġ- Ġ85 Ġdiagonal Ġelectronics Ġ- Ġgeneral Ġelite Ġscreens Ġr 85 wh 1 - wide Ġ409 . 0 </s> </s> Ġc ine gray Ġe z frame Ġseries Ġfixed Ġframe Ġscreen Ġ- Ġ150 Ġdiagonal Ġ8 79 . 0 Ġprojection Ġscreens Ġelite </s>
input_ids: 0 6281 8545 740 179 2753 298 1459 11605 23821 651 4460 5120 1810 2441 111 5663 42539 8917 111 937 6281 8545 910 4531 11613 134 12 6445 41781 4 288 2 2 740 833 42692 364 329 26061 651 4460 5120 2441 111 3982 42539 290 5220 4 288 18144 8545 6281 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: <s> Ġsan Ġdie go Ġpad res Ġ iph one Ġ4 Ġcase Ġsilicone Ġcover Ġelectronics Ġ- Ġgeneral Ġtrib eca Ġf va 39 59 Ġ24 . 99 </s> </s> Ġge org ia Ġbull dogs Ġ iph one Ġ4 Ġcase Ġsilicone Ġcover Ġtrib eca Ġ17 . 99 Ġcomputers Ġaccessories </s>
input_ids: 0 15610 1597 2977 11212 1535 1437 28778 1264 204 403 35453 1719 8917 111 937 28406 15366 856 3952 3416 4156 706 4 2831 2 2 5473 1957 493 8347 20226 1437 28778 1264 204 403 35453 1719 28406 15366 601 4 2831 7796 10131 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: <s> Ġinn over a Ġd 301 0 Ġblack Ġcompatible Ġhigh - y ield Ġton er Ġprint Ġcartridge Ġstation ery Ġ& Ġoffice Ġmachinery Ġd 301 0 Ġinn over a Ġ68 . 35 </s> </s> Ġpremium Ġcompatible Ġhp Ġ11 x Ġton er Ġcartridge Ġhp Ġq 65 11 x Ġ. Ġblack Ġprint Ġcartridge Ġhigh Ġyield Ġhp Ġ12 000 Ġpages Ġ. Ġ. Ġcompatible Ġink jet Ġprinter Ġink Ġhp - q 65 11 x Ġ28 . 92 </s>
input_ids: 0 22282 2137 102 385 28167 288 909 16632 239 12 219 8363 4866 254 5780 41785 1992 4270 359 558 13922 385 28167 288 22282 2137 102 5595 4 2022 2 2 4549 16632 29886 365 1178 4866 254 41785 29886 2231 3506 1225 1178 479 909 5780 41785 239 3363 29886 316 151 6052 479 479 16632 16019 6622 24079 16019 29886 12 1343 3506 1225 1178 971 4 6617 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: <s> Ġda - lite Ġda - plex Ġbase Ġrear Ġprojection Ġscreen Ġ- Ġ57 Ġ3 Ġ4 Ġx Ġ77 Ġvideo Ġformat Ġda - lite Ġ260 8 . 99 Ġelectronics Ġ- Ġgeneral Ġ275 28 </s> </s> Ġda - lite Ġ275 14 Ġda - plex Ġunf ram ed Ġrear Ġprojection Ġscreen Ġ- Ġ108 Ġx Ġ144 Ġvideo Ġformat Ġprojection Ġscreens Ġda - lite </s>
input_ids: 0 2955 12 33701 2955 12 26028 1542 5081 18144 2441 111 4981 155 204 3023 6791 569 7390 2955 12 33701 19809 398 4 2831 8917 111 937 25949 2517 2 2 2955 12 33701 25949 1570 2955 12 26028 9515 4040 196 5081 18144 2441 111 13955 3023 19641 569 7390 18144 8545 2955 12 33701 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: <s> Ġpc Ġtreasures Ġwireless Ġoptical Ġmouse Ġ2 . 4 Ġgh z Ġpurple Ġ07 227 Ġmice Ġpc Ġtreasures Ġ17 . 82 </s> </s> Ġinland Ġpro Ġ2 . 4 Ġgh z Ġwireless Ġoptical Ġmouse Ġ07 441 Ġ12 . 98 Ġmice Ġinland </s>
input_ids: 0 46213 30981 6955 17547 18292 132 4 306 34648 329 14327 13470 29240 15540 46213 30981 601 4 6551 2 2 18109 1759 132 4 306 34648 329 6955 17547 18292 13470 36011 316 4 5208 15540 18109 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-4102' was too long (tokens_a:66, tokens_b:86). Max_seq_length is 146, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 6144
  Batch size = 16
  Max Sequence Length = 150
loaded 6144 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 2049
*** Example ***
guid: test-0
tokens: <s> Ġs ony Ġ16 gb Ġclass Ġ4 Ġsd Ġmemory Ġcard Ġs ony Ġ0 . 0 Ġusb Ġdrives Ġs f 16 n 4 / t q p </s> </s> Ġp ny Ġ4 gb Ġclass Ġ4 Ġnavy Ġsd Ġcard Ġcar Ġaudio Ġvideo Ġp ny Ġp - sd h c 4 g 4 - ef Ġ/ Ġnavy Ġ11 . 18 </s>
input_ids: 0 579 6119 545 19562 1380 204 46409 3783 1886 579 6119 321 4 288 49030 6790 579 506 1549 282 306 73 90 1343 642 2 2 181 2855 204 19562 1380 204 13504 46409 1886 512 6086 569 181 2855 181 12 28045 298 438 306 571 306 12 4550 1589 13504 365 4 1366 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: <s> Ġz ot ac Ġg ef orce Ġg t 430 Ġ1 gb Ġd dr 3 Ġpci - express Ġ2 . 0 Ġgraphics Ġcard Ġz ot ac Ġelectronics Ġ- Ġgeneral Ġz t - 40 604 - 10 l Ġ88 . 88 </s> </s> Ġev ga Ġg ef orce Ġg ts 450 Ġsuper cl ocked Ġ1 Ġg b Ġg dd r 5 Ġpci - express Ġ2 . 0 Ġgraphics Ġcard Ġ01 g - p 3 - 14 52 - tr Ġgraphics Ġcards Ġev ga Ġ01 g - p 3 - 14 52 - tr Ġ119 . 88 </s>
input_ids: 0 992 1242 1043 821 4550 34260 821 90 29821 112 19562 385 10232 246 49899 12 37752 132 4 288 12774 1886 992 1242 1043 8917 111 937 992 90 12 1749 33287 12 698 462 7953 4 4652 2 2 7630 2538 821 4550 34260 821 1872 13872 2422 3998 9596 112 821 428 821 16134 338 245 49899 12 37752 132 4 288 12774 1886 9465 571 12 642 246 12 1570 4429 12 4328 12774 3591 7630 2538 9465 571 12 642 246 12 1570 4429 12 4328 16491 4 4652 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: <s> Ġda - lite Ġhigh Ġpower Ġmodel Ġb Ġmanual Ġscreen Ġwith Ġc sr Ġ- Ġ84 Ġx Ġ84 Ġav Ġformat Ġelectronics Ġ- Ġgeneral Ġda - lite Ġ85 303 Ġ372 . 99 </s> </s> Ġda - lite Ġadvantage Ġmanual Ġwith Ġc sr Ġ- Ġprojection Ġscreen Ġ- Ġ133 Ġin Ġ- Ġ16 Ġ9 Ġ- Ġhigh Ġpower Ġda - lite Ġ9 04 . 95 Ġhome Ġaudio Ġtheater </s>
input_ids: 0 2955 12 33701 239 476 1421 741 12769 2441 19 740 37959 111 7994 3023 7994 6402 7390 8917 111 937 2955 12 33701 5663 29274 41717 4 2831 2 2 2955 12 33701 2093 12769 19 740 37959 111 18144 2441 111 21448 11 111 545 361 111 239 476 2955 12 33701 361 3387 4 4015 184 6086 7364 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: <s> Ġda - lite Ġh c Ġcinema Ġvision Ġtension ed Ġadvantage Ġelect rol Ġ- Ġav Ġformat Ġ8 Ġx Ġ8 Ġdiagonal Ġelectronics Ġ- Ġgeneral Ġda - lite Ġ8 99 39 Ġ25 95 . 0 </s> </s> Ġh c Ġda - mat Ġtension ed Ġadvantage Ġelect rol Ġ- Ġav Ġformat Ġ50 Ġx Ġ50 Ġda - lite Ġprojection Ġscreens </s>
input_ids: 0 2955 12 33701 1368 438 11605 3360 8556 196 2093 10371 9396 111 6402 7390 290 3023 290 42539 8917 111 937 2955 12 33701 290 2831 3416 564 4015 4 288 2 2 1368 438 2955 12 9244 8556 196 2093 10371 9396 111 6402 7390 654 3023 654 2955 12 33701 18144 8545 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: <s> Ġver bat im Ġ4 gb Ġt uff Ġ- Ġn Ġ- Ġtiny Ġusb Ġ2 . 0 Ġflash Ġdrive Ġgreen Ġusb Ġdrives Ġver bat im Ġ11 . 98 </s> </s> Ġver bat im Ġclip - it Ġ4 Ġg b Ġusb Ġ2 . 0 Ġflash Ġdrive Ġ9 75 56 Ġgreen Ġusb Ġflash Ġdrives Ġ10 . 98 Ġver bat im Ġ9 75 56 </s>
input_ids: 0 4342 12161 757 204 19562 326 5865 111 295 111 5262 49030 132 4 288 7462 1305 2272 49030 6790 4342 12161 757 365 4 5208 2 2 4342 12161 757 7200 12 405 204 821 428 49030 132 4 288 7462 1305 361 2545 4419 2272 49030 7462 6790 158 4 5208 4342 12161 757 361 2545 4419 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 2049
  Batch size = 16
  Max Sequence Length = 150
loaded and initialized evaluation examples 2049
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.753188831861629
f1_score: 0.17216770740410348
simple_accuracy: 0.09419228892142509
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1856
           1       0.09      1.00      0.17       193

    accuracy                           0.09      2049
   macro avg       0.05      0.50      0.09      2049
weighted avg       0.01      0.09      0.02      2049

[1;33mStart dirty_dblp_acm roBERTa [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_acm
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=roberta-base
argument: model_type=roberta
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_acm
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/zye/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/zye/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
initialized roberta-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 7417
*** Example ***
guid: train-0
tokens: <s> Ġweb Ġcaching Ġfor Ġdatabase Ġapplications Ġwith Ġor acle Ġweb Ġcache Ġj ordan Ġpark er Ġ, Ġj esse Ġan ton Ġ, Ġz heng Ġz eng Ġ, Ġlaw rence Ġj ac obs Ġ, Ġtie Ġz h ong Ġ, Ġx iang Ġli u Ġsig mod Ġconference Ġ2002 . 0 </s> </s> Ġform - based Ġproxy Ġcaching Ġfor Ġdatabase - backed Ġweb Ġsites Ġvery Ġlarge Ġdata Ġbases Ġq ion g Ġl uo Ġ, Ġje ff rey Ġf . Ġn augh ton Ġ2001 . 0 </s>
input_ids: 0 3748 44499 13 8503 2975 19 50 24618 3748 30283 1236 29742 2221 254 2156 1236 19616 41 1054 2156 992 31075 992 3314 2156 488 21557 1236 1043 14247 2156 3318 992 298 1657 2156 3023 14607 16787 257 17224 14377 1019 5241 4 288 2 2 1026 12 805 16453 44499 13 8503 12 6996 3748 3091 182 739 414 7531 2231 1499 571 784 23613 2156 4112 3145 5460 856 4 295 11675 1054 5155 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: <s> Ġor acle Ġindustrial Ġexhibit Ġ1998 Ġamy Ġp ogue Ġv ld b </s> </s> Ġobject ivity Ġindustrial Ġexhibit Ġobject ivity Ġvery Ġlarge Ġdata Ġbases Ġ1998 . 0 </s>
input_ids: 0 50 24618 2683 8483 6708 45024 181 10149 748 4779 428 2 2 7626 9866 2683 8483 7626 9866 182 739 414 7531 6708 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: <s> Ġextracting Ġlarge - scale Ġknowledge Ġbases Ġfrom Ġthe Ġweb Ġand rew Ġtom kins Ġ, Ġpr ab hak ar Ġr agh avan Ġ, Ġr avi Ġk umar Ġ, Ġs rid har Ġr aj ag op alan Ġv ld b Ġ1999 . 0 </s> </s> Ġamalg am ating Ġknowledge Ġbases Ġv . Ġs . Ġsub rah man ian Ġac m Ġtransactions Ġon Ġdatabase Ġsystems Ġ( Ġto ds Ġ) Ġ1994 . 0 </s>
input_ids: 0 37213 739 12 8056 2655 7531 31 5 3748 8 10461 23681 7327 2156 3349 873 28832 271 910 7669 10937 2156 910 11132 449 16160 2156 579 10505 4759 910 1176 1073 1517 17330 748 4779 428 6193 4 288 2 2 34818 424 1295 2655 7531 748 4 579 4 2849 9772 397 811 4285 119 5538 15 8503 1743 36 7 11622 4839 8148 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: <s> Ġefficient Ġoptimistic Ġconc urrency Ġcontrol Ġusing Ġloosely Ġsynchronized Ġclocks Ġsig mod Ġconference Ġbar bara Ġl isk ov Ġ, Ġat ul Ġad ya Ġ, Ġro bert Ġgru ber Ġ, Ġum esh Ġma hes hw ari Ġ1995 . 0 </s> </s> Ġefficient Ġoptimistic Ġconc urrency Ġcontrol Ġusing Ġloosely Ġsynchronized Ġclocks Ġat ul Ġad ya Ġ, Ġro bert Ġgru ber Ġ, Ġbar bara Ġl isk ov Ġ, Ġum esh Ġma hes hw ari Ġinternational Ġconference Ġon Ġmanagement Ġof Ġdata Ġ1995 . 0 </s>
input_ids: 0 5693 7168 10146 37079 797 634 29213 40854 29130 17224 14377 1019 2003 31533 784 6812 1417 2156 23 922 2329 2636 2156 4533 6747 15551 1943 2156 7252 4891 9131 5065 30826 1512 7969 4 288 2 2 5693 7168 10146 37079 797 634 29213 40854 29130 23 922 2329 2636 2156 4533 6747 15551 1943 2156 2003 31533 784 6812 1417 2156 7252 4891 9131 5065 30826 1512 758 1019 15 1052 9 414 7969 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-4
tokens: <s> Ġo def s Ġ: Ġa Ġfile Ġsystem Ġinterface Ġto Ġan Ġobject - oriented Ġdatabase Ġnar ain Ġh . Ġge hani Ġ, Ġwill iam Ġd . Ġro ome Ġ, Ġh . Ġv . Ġj ag adish Ġv ld b Ġ1994 . 0 </s> </s> Ġun is ql / x Ġunified Ġrelational Ġand Ġobject - oriented Ġdatabase Ġsystem Ġwon Ġk im Ġ1994 Ġinternational Ġconference Ġon Ġmanagement Ġof Ġdata </s>
input_ids: 0 1021 9232 29 4832 10 2870 467 12332 7 41 7626 12 13283 8503 34139 1851 1368 4 5473 36424 2156 40 6009 385 4 4533 4399 2156 1368 4 748 4 1236 1073 30068 748 4779 428 8148 4 288 2 2 542 354 44306 73 1178 16681 45279 8 7626 12 13283 8503 467 351 449 757 8148 758 1019 15 1052 9 414 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-269' was too long (tokens_a:86, tokens_b:95). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-1056' was too long (tokens_a:91, tokens_b:91). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-1351' was too long (tokens_a:126, tokens_b:53). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-2039' was too long (tokens_a:92, tokens_b:92). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-2076' was too long (tokens_a:152, tokens_b:32). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-2293' was too long (tokens_a:54, tokens_b:136). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-2443' was too long (tokens_a:93, tokens_b:100). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-2770' was too long (tokens_a:133, tokens_b:133). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-3388' was too long (tokens_a:95, tokens_b:100). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-3897' was too long (tokens_a:135, tokens_b:134). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-4202' was too long (tokens_a:67, tokens_b:117). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-4433' was too long (tokens_a:68, tokens_b:112). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-4613' was too long (tokens_a:104, tokens_b:105). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-5050' was too long (tokens_a:99, tokens_b:101). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-5238' was too long (tokens_a:126, tokens_b:105). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-5951' was too long (tokens_a:106, tokens_b:107). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-6024' was too long (tokens_a:126, tokens_b:60). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-6632' was too long (tokens_a:120, tokens_b:122). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-6640' was too long (tokens_a:85, tokens_b:92). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-6755' was too long (tokens_a:110, tokens_b:105). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-6843' was too long (tokens_a:99, tokens_b:101). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-7223' was too long (tokens_a:89, tokens_b:93). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'train-7359' was too long (tokens_a:91, tokens_b:92). Max_seq_length is 176, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 7417
  Batch size = 16
  Max Sequence Length = 180
loaded 7417 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 2473
*** Example ***
guid: test-0
tokens: <s> Ġsecure Ġtransaction Ġprocessing Ġin Ġfirm Ġreal - time Ġdatabase Ġsystems Ġb into Ġge orge Ġ, Ġj ay ant Ġr . Ġhar its a Ġsig mod Ġconference Ġ1997 . 0 </s> </s> Ġsecure Ġbuff ering Ġin Ġfirm Ġreal - time Ġdatabase Ġsystems Ġ2000 Ġb into Ġge orge Ġ, Ġj ay ant Ġr . Ġhar its a Ġthe Ġv ld b Ġjournal Ġ-- Ġthe Ġinternational Ġjournal Ġon Ġvery Ġlarge Ġdata Ġbases </s>
input_ids: 0 2823 2676 5774 11 933 588 12 958 8503 1743 741 12473 5473 26875 2156 1236 857 927 910 4 12280 2629 102 17224 14377 1019 7528 4 288 2 2 2823 27793 2961 11 933 588 12 958 8503 1743 3788 741 12473 5473 26875 2156 1236 857 927 910 4 12280 2629 102 5 748 4779 428 8812 480 5 758 8812 15 182 739 414 7531 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: <s> Ġclust ering Ġvalidity Ġchecking Ġmethods Ġ: Ġpart Ġii Ġm ich alis Ġv az ir gian nis Ġ, Ġmar ia Ġh alk idi Ġ, Ġy annis Ġbat ist akis Ġsig mod Ġrecord Ġ2002 . 0 </s> </s> Ġcluster Ġvalidity Ġmethods Ġ: Ġpart Ġi Ġ2002 Ġmar ia Ġh alk idi Ġ, Ġy annis Ġbat ist akis Ġ, Ġm ich alis Ġv az ir gian nis Ġac m Ġsig mod Ġrecord </s>
input_ids: 0 46644 2961 25295 8405 6448 4832 233 42661 475 1725 21133 748 1222 853 42859 10892 2156 4401 493 1368 9707 12451 2156 1423 31539 6325 661 17622 17224 14377 638 5241 4 288 2 2 18016 25295 6448 4832 233 939 5241 4401 493 1368 9707 12451 2156 1423 31539 6325 661 17622 2156 475 1725 21133 748 1222 853 42859 10892 4285 119 17224 14377 638 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: <s> Ġa Ġquery Ġlanguage Ġand Ġoptimization Ġtechniques Ġfor Ġun struct ured Ġdata Ġger d Ġg . Ġh ille brand Ġ, Ġp eter Ġbun eman Ġ, Ġsus an Ġb . Ġdavid son Ġ, Ġdan Ġsu ci u Ġsig mod Ġconference Ġ1996 . 0 </s> </s> Ġfundamental Ġtechniques Ġfor Ġorder Ġoptimization Ġdavid Ġsim men Ġ, Ġe ug ene Ġshe k ita Ġ, Ġtim othy Ġmal ke mus Ġinternational Ġconference Ġon Ġmanagement Ġof Ġdata Ġ1996 . 0 </s>
input_ids: 0 10 25860 2777 8 25212 7373 13 542 25384 4075 414 18250 417 821 4 1368 4061 11638 2156 181 5906 15713 5649 2156 12495 260 741 4 44009 1478 2156 20435 2628 2520 257 17224 14377 1019 8008 4 288 2 2 6451 7373 13 645 25212 44009 16207 2262 2156 364 3252 2552 79 330 3119 2156 15679 37994 8196 1071 13792 758 1019 15 1052 9 414 8008 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: <s> Ġstructures Ġfor Ġmanipulating Ġproposed Ġupdates Ġin Ġobject - oriented Ġdatabases Ġrich ard Ġhull Ġ, Ġm oh ammed Ġr up aw alla Ġ, Ġm ichael Ġdo herty Ġ1996 Ġsig mod Ġconference </s> </s> Ġobservations Ġon Ġthe Ġod mg - 93 Ġproposal Ġfor Ġan Ġobject - oriented Ġdatabase Ġlanguage Ġwon Ġk im Ġac m Ġsig mod Ġrecord Ġ1994 . 0 </s>
input_ids: 0 6609 13 30830 1850 3496 11 7626 12 13283 22578 4066 1120 31594 2156 475 2678 21639 910 658 1584 13421 2156 475 25554 109 14076 8008 17224 14377 1019 2 2 15864 15 5 7452 22984 12 6478 2570 13 41 7626 12 13283 8503 2777 351 449 757 4285 119 17224 14377 638 8148 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: <s> Ġintegrating Ġa Ġstructured - text Ġretrieval Ġsystem Ġwith Ġan Ġobject - oriented Ġdatabase Ġsystem Ġj urg en Ġan ne vel ink Ġ, Ġt ak Ġw . Ġy an Ġv ld b Ġ1994 . 0 </s> </s> Ġindex Ġnesting Ġ- Ġan Ġefficient Ġapproach Ġto Ġindex ing Ġin Ġobject - oriented Ġdatabases Ġb eng Ġchin Ġo oi Ġ, Ġj ia wei Ġh an Ġ, Ġh ong jun Ġl u Ġ, Ġk ian Ġle e Ġtan Ġthe Ġv ld b Ġjournal Ġ-- Ġthe Ġinternational Ġjournal Ġon Ġvery Ġlarge Ġdata Ġbases Ġ1996 </s>
input_ids: 0 22688 10 16697 12 29015 43372 467 19 41 7626 12 13283 8503 467 1236 7150 225 41 858 5536 4291 2156 326 677 885 4 1423 260 748 4779 428 8148 4 288 2 2 1965 36416 111 41 5693 1548 7 1965 154 11 7626 12 13283 22578 741 3314 23223 1021 12467 2156 1236 493 21225 1368 260 2156 1368 1657 18115 784 257 2156 449 811 2084 242 15149 5 748 4779 428 8812 480 5 758 8812 15 182 739 414 7531 8008 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'test-708' was too long (tokens_a:110, tokens_b:85). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'test-1399' was too long (tokens_a:100, tokens_b:101). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'test-1626' was too long (tokens_a:128, tokens_b:123). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'test-2158' was too long (tokens_a:110, tokens_b:69). Max_seq_length is 176, so we reduce it in a smart way
Sample with ID 'test-2398' was too long (tokens_a:116, tokens_b:112). Max_seq_length is 176, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 2473
  Batch size = 16
  Max Sequence Length = 180
loaded and initialized evaluation examples 2473
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7359617629358846
f1_score: 0.3044223517312307
simple_accuracy: 0.17953902143145978
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      2029
           1       0.18      1.00      0.30       444

    accuracy                           0.18      2473
   macro avg       0.09      0.50      0.15      2473
weighted avg       0.03      0.18      0.05      2473

[1;33mStart dirty_dblp_scholar roBERTa [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_scholar
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=roberta-base
argument: model_type=roberta
argument: do_lower_case=True
argument: max_seq_length=128
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_scholar
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/zye/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/zye/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
initialized roberta-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 17223
*** Example ***
guid: train-0
tokens: <s> Ġthe Ġdem arc ation Ġprotocol Ġ: Ġa Ġtechnique Ġfor Ġmaintaining Ġconstraints Ġin Ġdistributed Ġdatabase Ġsystems Ġv ld b Ġj . Ġ1994 Ġd Ġbarbar Ñģ Ġ, Ġh Ġgar cia - mol ina </s> </s> Ġlocal Ġverification Ġof Ġglobal Ġintegrity Ġconstraints Ġin Ġdistributed Ġdatabases Ġa Ġgu pta Ġ, Ġj Ġwid om </s>
input_ids: 0 5 4410 9636 1258 11883 4832 10 9205 13 6780 16311 11 7664 8503 1743 748 4779 428 1236 4 8148 385 41503 36709 2156 1368 15475 14555 12 37145 1243 2 2 400 14925 9 720 7066 16311 11 7664 22578 10 11843 25890 2156 1236 23772 1075 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: <s> Ġon - demand Ġdata Ġelevation Ġin Ġhierarchical Ġmultimedia Ġstorage Ġservers Ġv ld b Ġp Ġtri ant af ill ou Ġ, Ġt Ġpap ad akis Ġ1997 . 0 </s> </s> Ġon - demand Ġdata Ġelevation Ġin Ġa Ġhierarchical Ġmultimedia Ġstorage Ġserver Ġproc Ġ. Ġof Ġ23 rd Ġint l . Ġconf Ġ. Ġon Ġvery Ġlarge Ġdata Ġbases Ġ, Ġv ld b Ġ, Ġp Ġtri ant all ou Ġ, Ġt Ġpap ad akis Ġ1997 . 0 </s>
input_ids: 0 15 12 15509 414 25361 11 44816 15778 3521 13282 748 4779 428 181 7182 927 2001 1873 1438 2156 326 13102 625 17622 7528 4 288 2 2 15 12 15509 414 25361 11 10 44816 15778 3521 10228 17987 479 9 883 2586 6979 462 4 7856 479 15 182 739 414 7531 2156 748 4779 428 2156 181 7182 927 1250 1438 2156 326 13102 625 17622 7528 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-2
tokens: <s> Ġdatabase Ġtuning Ġ: Ġprinciples Ġ, Ġexperiments Ġ, Ġand Ġtroubles hooting Ġtechniques Ġd Ġsh asha Ġ, Ġp Ġbon net Ġv ld b Ġ2002 </s> </s> Ġdatabase Ġtuning Ġ: Ġprinciples Ġ, Ġexperiments Ġ, Ġand Ġtroubles hooting Ġtechniques Ġ( Ġpart Ġi Ġ) Ġ2002 . 0 Ġd Ġsh asha Ġ, Ġp Ġbon net Ġproceedings Ġof Ġthe Ġ2002 Ġac m Ġsig mod Ġinternational Ġconference Ġ& Ġhell ip Ġ; Ġ, </s>
input_ids: 0 8503 28927 4832 7797 2156 15491 2156 8 13656 41086 7373 385 1481 15144 2156 181 13295 4135 748 4779 428 5241 2 2 8503 28927 4832 7797 2156 15491 2156 8 13656 41086 7373 36 233 939 4839 5241 4 288 385 1481 15144 2156 181 13295 4135 7069 9 5 5241 4285 119 17224 14377 758 1019 359 7105 1588 25606 2156 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-3
tokens: <s> Ġd na - min er Ġ: Ġa Ġsystem Ġprototype Ġfor Ġmining Ġd na Ġsequences Ġsig mod Ġconference Ġ2001 Ġj Ġh an Ġ, Ġh Ġjam il Ġ, Ġy Ġl u Ġ, Ġl Ġc hen Ġ, Ġy Ġl iao Ġ, Ġj Ġpe i </s> </s> Ġn . Ġst ef an ovic Ġ1997 ĠÃ ¢ Ġ?? Ġge omin er Ġ: Ġa Ġsystem Ġprototype Ġfor Ġspatial Ġdata Ġmining Ã¢ Ġ?? Ġj Ġh an Ġ, Ġk Ġk opers ki Ġproc Ġ. Ġac m - s ig mod Ġint Ġ. Ġconf Ġ. Ġon Ġmanagement Ġof Ġdata Ġ( Ġsig mod Ġ& # 39 ; Ġ97 </s>
input_ids: 0 385 2133 12 4691 254 4832 10 467 17715 13 4481 385 2133 26929 17224 14377 1019 5155 1236 1368 260 2156 1368 11914 718 2156 1423 784 257 2156 784 740 2457 2156 1423 784 17530 2156 1236 3723 118 2 2 295 4 1690 4550 260 4834 7528 952 7258 42254 5473 18121 254 4832 10 467 17715 13 34999 414 4481 3695 42254 1236 1368 260 2156 449 449 18158 3144 17987 479 4285 119 12 29 1023 14377 6979 479 7856 479 15 1052 9 414 36 17224 14377 359 10431 3416 131 8783 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: <s> Ġcommunication Ġefficient Ġdistributed Ġmining Ġof Ġassociation Ġrules Ġsig mod Ġconference Ġ2001 Ġa Ġsch uster Ġ, Ġr Ġw ol ff </s> </s> Ġmining Ġgeneralized Ġassociation Ġrules Ġr Ġag raw al Ġ, Ġr Ġs rik ant Ġproceedings Ġof Ġthe Ġ1995 Ġinternational Ġconference Ġof Ġvery Ġ& Ġhell ip Ġ; Ġ, </s>
input_ids: 0 4358 5693 7664 4481 9 5259 1492 17224 14377 1019 5155 10 8447 10504 2156 910 885 1168 3145 2 2 4481 44030 5259 1492 910 5951 9056 337 2156 910 579 8836 927 7069 9 5 7969 758 1019 9 182 359 7105 1588 25606 2156 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-288' was too long (tokens_a:79, tokens_b:48). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-731' was too long (tokens_a:98, tokens_b:53). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-1213' was too long (tokens_a:85, tokens_b:41). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-2056' was too long (tokens_a:98, tokens_b:42). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-2415' was too long (tokens_a:83, tokens_b:56). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-2486' was too long (tokens_a:86, tokens_b:45). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-2647' was too long (tokens_a:73, tokens_b:63). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-2993' was too long (tokens_a:83, tokens_b:50). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-3159' was too long (tokens_a:85, tokens_b:58). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-3658' was too long (tokens_a:63, tokens_b:62). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-4981' was too long (tokens_a:85, tokens_b:40). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-6413' was too long (tokens_a:100, tokens_b:62). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-6460' was too long (tokens_a:98, tokens_b:44). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-6625' was too long (tokens_a:85, tokens_b:41). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-7422' was too long (tokens_a:85, tokens_b:40). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-9808' was too long (tokens_a:85, tokens_b:45). Max_seq_length is 124, so we reduce it in a smart way
Writing example 10000 of 17223
Sample with ID 'train-10084' was too long (tokens_a:85, tokens_b:43). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-10155' was too long (tokens_a:82, tokens_b:62). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-11179' was too long (tokens_a:100, tokens_b:46). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-11869' was too long (tokens_a:88, tokens_b:54). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-13147' was too long (tokens_a:82, tokens_b:46). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-13665' was too long (tokens_a:94, tokens_b:46). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-13964' was too long (tokens_a:98, tokens_b:34). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-14349' was too long (tokens_a:126, tokens_b:30). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-14999' was too long (tokens_a:94, tokens_b:31). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-15037' was too long (tokens_a:85, tokens_b:42). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-15340' was too long (tokens_a:100, tokens_b:44). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-15351' was too long (tokens_a:85, tokens_b:43). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-15903' was too long (tokens_a:85, tokens_b:55). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-16720' was too long (tokens_a:100, tokens_b:40). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'train-16818' was too long (tokens_a:88, tokens_b:46). Max_seq_length is 124, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 17223
  Batch size = 16
  Max Sequence Length = 128
loaded 17223 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 5742
*** Example ***
guid: test-0
tokens: <s> Ġcure Ġ: Ġan Ġefficient Ġclust ering Ġalgorithm Ġfor Ġlarge Ġdatabases Ġs Ġgu ha Ġ, Ġr Ġr ast ogi Ġ, Ġk Ġsh im Ġsig mod Ġconference Ġ1998 . 0 </s> </s> Ġefficient Ġalgorithm Ġfor Ġprojected Ġclust ering Ġen k Ġka Ġ, Ġaw Ġfu </s>
input_ids: 0 13306 4832 41 5693 46644 2961 17194 13 739 22578 579 11843 1999 2156 910 910 1988 22516 2156 449 1481 757 17224 14377 1019 6708 4 288 2 2 5693 17194 13 5635 46644 2961 1177 330 4661 2156 19267 14429 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: <s> Ġopen Ġobject Ġdatabase Ġmanagement Ġsystems Ġ1994 . 0 </s> </s> Ġperformance Ġevaluation Ġof Ġa Ġtemporal Ġdatabase Ġmanagement Ġsystem Ġi Ġa hn Ġ, Ġr Ġsn od grass Ġproceedings Ġof Ġthe Ġ1986 Ġac m Ġsig mod Ġinternational Ġconference Ġ& Ġhell ip Ġ; Ġ, Ġ1986 . 0 </s>
input_ids: 0 490 7626 8503 1052 1743 8148 4 288 2 2 819 10437 9 10 41853 8503 1052 467 939 10 10245 2156 910 4543 1630 17282 7069 9 5 11265 4285 119 17224 14377 758 1019 359 7105 1588 25606 2156 11265 4 288 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: <s> Ġan Ġefficient Ġalgorithm Ġfor Ġmining Ġassociation Ġrules Ġin Ġlarge Ġdatabases Ġa Ġsav as ere Ġ, Ġe Ġom ie c inski Ġ, Ġs Ġnav athe Ġv ld b Ġ1995 . 0 </s> </s> Ġmining Ġassociation Ġrules Ġbetween Ġsets Ġof Ġitems Ġin Ġlarge Ġdatabases Ġ. Ġ1993 Ġproc Ġ. Ġac m Ġsig mod Ġinternational Ġconference Ġon Ġmanagement Ġof Ġr Ġag raw al Ġ, Ġt Ġim iel inski Ġ, Ġa Ġsw ami </s>
input_ids: 0 41 5693 17194 13 4481 5259 1492 11 739 22578 10 14065 281 2816 2156 364 16780 324 438 12166 2156 579 31428 23872 748 4779 428 7969 4 288 2 2 4481 5259 1492 227 3880 9 1964 11 739 22578 479 9095 17987 479 4285 119 17224 14377 758 1019 15 1052 9 910 5951 9056 337 2156 326 4356 5255 12166 2156 10 3514 5602 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: <s> Ġformal Ġquery Ġlanguages Ġfor Ġsecure Ġrelational Ġdatabases Ġac m Ġtrans Ġ. Ġdatabase Ġsy st Ġ. Ġm Ġwins lett Ġ, Ġk Ġsm ith Ġ, Ġx Ġq ian Ġ1994 . 0 </s> </s> Ġa Ġvisual Ġquery Ġlanguage Ġfor Ġod mg - compl iant Ġdatabases Ġm Ġch av da Ġ, Ġpt Ġwood </s>
input_ids: 0 4828 25860 11991 13 2823 45279 22578 4285 119 6214 479 8503 13550 620 479 475 2693 8211 2156 449 5278 3432 2156 3023 2231 811 8148 4 288 2 2 10 7133 25860 2777 13 7452 22984 12 23391 9488 22578 475 1855 1469 6106 2156 46238 5627 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: <s> Ġa Ġlanguage Ġbased Ġmult id at abase Ġsystem Ġe Ġk Ñ ľ hn Ġ, Ġt Ġt sc hern ko Ġ, Ġk Ġsch war z Ġsig mod Ġconference Ġ1994 . 0 </s> </s> Ġa Ġclassification Ġof Ġmulti - database Ġlanguages Ġparallel Ġand Ġdistributed Ġinformation Ġsystems Ġ, Ġ1994 . Ġ, Ġ& Ġhell ip Ġ; Ġ, Ġ1994 . 0 Ġm Ġt res ch Ġ, Ġm h Ġsch oll Ġ, Ġib mar Ġcenter Ġ, Ġca Ġsan Ġj ose </s>
input_ids: 0 10 2777 716 7268 808 415 46972 467 364 449 22063 48 10245 2156 326 326 3866 16494 3852 2156 449 8447 5557 329 17224 14377 1019 8148 4 288 2 2 10 20257 9 3228 12 48094 11991 12980 8 7664 335 1743 2156 8148 4 2156 359 7105 1588 25606 2156 8148 4 288 475 326 1535 611 2156 475 298 8447 3937 2156 34154 3916 1312 2156 6056 15610 1236 3876 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'test-940' was too long (tokens_a:85, tokens_b:45). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-1173' was too long (tokens_a:85, tokens_b:41). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-1372' was too long (tokens_a:100, tokens_b:27). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-1439' was too long (tokens_a:80, tokens_b:47). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-2226' was too long (tokens_a:67, tokens_b:59). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-2261' was too long (tokens_a:126, tokens_b:34). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-2492' was too long (tokens_a:126, tokens_b:14). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-3194' was too long (tokens_a:85, tokens_b:46). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-3953' was too long (tokens_a:85, tokens_b:47). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-5141' was too long (tokens_a:85, tokens_b:43). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-5210' was too long (tokens_a:98, tokens_b:57). Max_seq_length is 124, so we reduce it in a smart way
Sample with ID 'test-5700' was too long (tokens_a:86, tokens_b:43). Max_seq_length is 124, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 5742
  Batch size = 16
  Max Sequence Length = 128
loaded and initialized evaluation examples 5742
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7359636264923223
f1_score: 0.3141514973576042
simple_accuracy: 0.18634622082897945
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      4672
           1       0.19      1.00      0.31      1070

    accuracy                           0.19      5742
   macro avg       0.09      0.50      0.16      5742
weighted avg       0.03      0.19      0.06      5742

[1;33mStart dirty_amazon_itunes BERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_amazon_itunes
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=pre_trained_model/bert-base-uncased
argument: model_type=bert
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_amazon_itunes
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
Model name 'pre_trained_model/bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'pre_trained_model/bert-base-uncased' was a path or url but couldn't find any file associated to this path or url.
[1;33mStart abt_buy BERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=abt_buy
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=pre_trained_model/bert-base-uncased
argument: model_type=bert
argument: do_lower_case=True
argument: max_seq_length=265
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/abt_buy
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
Model name 'pre_trained_model/bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'pre_trained_model/bert-base-uncased' was a path or url but couldn't find any file associated to this path or url.
[1;33mStart dirty_walmart_amazon BERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_walmart_amazon
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=pre_trained_model/bert-base-uncased
argument: model_type=bert
argument: do_lower_case=True
argument: max_seq_length=150
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_walmart_amazon
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
Model name 'pre_trained_model/bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'pre_trained_model/bert-base-uncased' was a path or url but couldn't find any file associated to this path or url.
[1;33mStart dirty_dblp_acm BERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_acm
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=pre_trained_model/bert-base-uncased
argument: model_type=bert
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_acm
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
Model name 'pre_trained_model/bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'pre_trained_model/bert-base-uncased' was a path or url but couldn't find any file associated to this path or url.
[1;33mStart dirty_dblp_scholar BERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_scholar
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=pre_trained_model/bert-base-uncased
argument: model_type=bert
argument: do_lower_case=True
argument: max_seq_length=128
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_scholar
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
Model name 'pre_trained_model/bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'pre_trained_model/bert-base-uncased' was a path or url but couldn't find any file associated to this path or url.
[1;33mStart dirty_amazon_itunes DistilBERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_amazon_itunes
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=distilbert-base-uncased
argument: model_type=distilbert
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_amazon_itunes
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c
Model config {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": null,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "torchscript": false,
  "vocab_size": 30522
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/zye/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5
Weights of DistilBertForSequenceClassification not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
Weights from pretrained model not used in DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']
initialized distilbert-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 321
*** Example ***
guid: train-0
tokens: [CLS] illusion ( feat . echo ##smith ) ze ##dd true colors dance , music , electronic 2015 inter ##scope records 6 : 30 $ 1 . 29 18 - may - 15 [SEP] transmission [ feat . x ambassadors ] dance & electronic $ 1 . 29 ( c ) 2015 inter ##scope records 4 : 02 ze ##dd true colors may 18 , 2015 [SEP]
input_ids: 101 12492 1006 8658 1012 9052 21405 1007 27838 14141 2995 6087 3153 1010 2189 1010 4816 2325 6970 26127 2636 1020 1024 2382 1002 1015 1012 2756 2324 1011 2089 1011 2321 102 6726 1031 8658 1012 1060 20986 1033 3153 1004 4816 1002 1015 1012 2756 1006 1039 1007 2325 6970 26127 2636 1018 1024 6185 27838 14141 2995 6087 2089 2324 1010 2325 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: [CLS] i ' m a machine ( feat . crystal nicole and tyres ##e gibson ) dance , music , rock , house , electronic 26 - aug - 11 david gu ##etta nothing but the beat $ 1 . 29 2011 what a music ltd , licence exclusive par ##lo ##phone music france 3 : 34 [SEP] i can only imagine ( feat . chris brown & lil wayne ) david gu ##etta dance & electronic 2015 real sounds 3 : 29 august 26 , 2011 nothing but the beat 2 . 0 [ explicit ] $ 0 . 99 [SEP]
input_ids: 101 1045 1005 1049 1037 3698 1006 8658 1012 6121 9851 1998 24656 2063 9406 1007 3153 1010 2189 1010 2600 1010 2160 1010 4816 2656 1011 15476 1011 2340 2585 19739 16549 2498 2021 1996 3786 1002 1015 1012 2756 2249 2054 1037 2189 5183 1010 11172 7262 11968 4135 9864 2189 2605 1017 1024 4090 102 1045 2064 2069 5674 1006 8658 1012 3782 2829 1004 13451 6159 1007 2585 19739 16549 3153 1004 4816 2325 2613 4165 1017 1024 2756 2257 2656 1010 2249 2498 2021 1996 3786 1016 1012 1014 1031 13216 1033 1002 1014 1012 5585 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: [CLS] silver and gold 3 : 33 little big town pain killer country , music , hon ##ky ton ##k , contemporary country $ 1 . 29 2014 little big town , llc under exclusive license to capitol records nashville 21 - oct - 14 [SEP] silver and gold little big town country ( c ) 2014 little big town llc under exclusive license to capitol records nashville 3 : 31 pain killer $ 1 . 29 october 21 , 2014 [SEP]
input_ids: 101 3165 1998 2751 1017 1024 3943 2210 2502 2237 3255 6359 2406 1010 2189 1010 10189 4801 10228 2243 1010 3824 2406 1002 1015 1012 2756 2297 2210 2502 2237 1010 11775 2104 7262 6105 2000 9424 2636 8423 2538 1011 13323 1011 2403 102 3165 1998 2751 2210 2502 2237 2406 1006 1039 1007 2297 2210 2502 2237 11775 2104 7262 6105 2000 9424 2636 8423 1017 1024 2861 3255 6359 1002 1015 1012 2756 2255 2538 1010 2297 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-3
tokens: [CLS] dangerous ( feat . sam martin ) [ robin sc ##hul ##z remix ] [ radio edit ] david gu ##etta dance , music , rock , house , electronic , french pop $ 1 . 29 2014 what a music ltd . under exclusive license to par ##lo ##phone / warner music france , under exclusive license to atlantic recording corporation for the united states . all rights reserved . 24 - nov - 14 listen ( deluxe version ) 3 : 20 [SEP] i ' ll keep loving you ( feat . bird ##y & jay ##mes young ) david gu ##etta listen ( deluxe ) $ 1 . 29 2015 if moving your mine november 24 , 2014 dance & electronic 3 : 08 [SEP]
input_ids: 101 4795 1006 8658 1012 3520 3235 1007 1031 5863 8040 21886 2480 6136 1033 1031 2557 10086 1033 2585 19739 16549 3153 1010 2189 1010 2600 1010 2160 1010 4816 1010 2413 3769 1002 1015 1012 2756 2297 2054 1037 2189 5183 1012 2104 7262 6105 2000 11968 4135 9864 1013 6654 2189 2605 1010 2104 7262 6105 2000 4448 3405 3840 2005 1996 2142 2163 1012 2035 2916 9235 1012 2484 1011 13292 1011 2403 4952 1006 15203 2544 1007 1017 1024 2322 102 1045 1005 2222 2562 8295 2017 1006 8658 1012 4743 2100 1004 6108 7834 2402 1007 2585 19739 16549 4952 1006 15203 1007 1002 1015 1012 2756 2325 2065 3048 2115 3067 2281 2484 1010 2297 3153 1004 4816 1017 1024 5511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: [CLS] true colors ( feat . nick ##i mina ##j ) wi ##z khalifa hip - hop / rap , music , rap , east coast rap , hardcore rap , rock 4 : 15 19 - aug - 14 b ##la ##cc hollywood $ 1 . 29 2014 atlantic recording corporation for the united states and we ##a international inc . for the world outside of the united states . a warner music group company [SEP] still down ( feat . chevy woods & ty doll ##a $ ign ) [ explicit ] $ 1 . 29 2014 atlantic recording corporation for the united states and we ##a international inc . for the world outside of the united states . a warner music group company 4 : 16 august 19 , 2014 wi ##z khalifa b ##la ##cc hollywood [ explicit ] rap & hip - hop [SEP]
input_ids: 101 2995 6087 1006 8658 1012 4172 2072 19808 3501 1007 15536 2480 27925 5099 1011 6154 1013 9680 1010 2189 1010 9680 1010 2264 3023 9680 1010 13076 9680 1010 2600 1018 1024 2321 2539 1011 15476 1011 2403 1038 2721 9468 5365 1002 1015 1012 2756 2297 4448 3405 3840 2005 1996 2142 2163 1998 2057 2050 2248 4297 1012 2005 1996 2088 2648 1997 1996 2142 2163 1012 1037 6654 2189 2177 2194 102 2145 2091 1006 8658 1012 29009 5249 1004 5939 10658 2050 1002 16270 1007 1031 13216 1033 1002 1015 1012 2756 2297 4448 3405 3840 2005 1996 2142 2163 1998 2057 2050 2248 4297 1012 2005 1996 2088 2648 1997 1996 2142 2163 1012 1037 6654 2189 2177 2194 1018 1024 2385 2257 2539 1010 2297 15536 2480 27925 1038 2721 9468 5365 1031 13216 1033 9680 1004 5099 1011 6154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-253' was too long (tokens_a:103, tokens_b:98). Max_seq_length is 177, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 321
  Batch size = 16
  Max Sequence Length = 180
loaded 321 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 109
*** Example ***
guid: test-0
tokens: [CLS] elevator ( feat . tim ##bala ##nd ) fl ##o rid ##a mail on sunday ( deluxe version ) hip - hop / rap , music , dirty south 3 : 55 17 - mar - 08 $ 1 . 99 2008 atlantic recording corporation for the united states and we ##a international inc . for the world outside of the united states [SEP] money right ( feat . rick ross & br ##is ##co ) [ explicit ] rap & hip - hop march 17 , 2008 fl ##o rid ##a mail on sunday [ explicit ] $ 1 . 29 2013 warner bros . . records inc . 3 : 17 [SEP]
input_ids: 101 7764 1006 8658 1012 5199 25060 4859 1007 13109 2080 9436 2050 5653 2006 4465 1006 15203 2544 1007 5099 1011 6154 1013 9680 1010 2189 1010 6530 2148 1017 1024 4583 2459 1011 9388 1011 5511 1002 1015 1012 5585 2263 4448 3405 3840 2005 1996 2142 2163 1998 2057 2050 2248 4297 1012 2005 1996 2088 2648 1997 1996 2142 2163 102 2769 2157 1006 8658 1012 6174 5811 1004 7987 2483 3597 1007 1031 13216 1033 9680 1004 5099 1011 6154 2233 2459 1010 2263 13109 2080 9436 2050 5653 2006 4465 1031 13216 1033 1002 1015 1012 2756 2286 6654 10243 1012 1012 2636 4297 1012 1017 1024 2459 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: [CLS] the woodland realm ( extended version ) howard shore the ho ##bb ##it : the des ##ola ##tion of sm ##au ##g ( original motion picture soundtrack ) [ special edition ] soundtrack , music , soundtrack , classical , original score $ 1 . 29 5 : 14 10 - dec - 13 ‰ an 2013 water ##tower music [SEP] the high fell ##s ( extended version ) the ho ##bb ##it : the des ##ola ##tion of sm ##au ##g ( original motion picture soundtrack ) [ special edition ] $ 1 . 29 2013 water ##tower music / warner bros . . entertainment / metro - gold ##wyn mayer pictures inc . december 10 , 2013 howard shore soundtracks 3 : 38 [SEP]
input_ids: 101 1996 11051 8391 1006 3668 2544 1007 4922 5370 1996 7570 10322 4183 1024 1996 4078 6030 3508 1997 15488 4887 2290 1006 2434 4367 3861 6050 1007 1031 2569 3179 1033 6050 1010 2189 1010 6050 1010 4556 1010 2434 3556 1002 1015 1012 2756 1019 1024 2403 2184 1011 11703 1011 2410 1530 2019 2286 2300 23196 2189 102 1996 2152 3062 2015 1006 3668 2544 1007 1996 7570 10322 4183 1024 1996 4078 6030 3508 1997 15488 4887 2290 1006 2434 4367 3861 6050 1007 1031 2569 3179 1033 1002 1015 1012 2756 2286 2300 23196 2189 1013 6654 10243 1012 1012 4024 1013 6005 1011 2751 11761 14687 4620 4297 1012 2285 2184 1010 2286 4922 5370 24245 1017 1024 4229 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: [CLS] extra extra credit wi ##z khalifa flight school $ 0 . 99 2009 ro ##st ##rum records 4 : 03 hip - hop / rap , music 17 - apr - 09 [SEP] extra extra credit [ explicit ] wi ##z khalifa 2013 mad decent flight school [ explicit ] rap & hip - hop $ 0 . 99 4 : 03 april 17 , 2009 [SEP]
input_ids: 101 4469 4469 4923 15536 2480 27925 3462 2082 1002 1014 1012 5585 2268 20996 3367 6824 2636 1018 1024 6021 5099 1011 6154 1013 9680 1010 2189 2459 1011 19804 1011 5641 102 4469 4469 4923 1031 13216 1033 15536 2480 27925 2286 5506 11519 3462 2082 1031 13216 1033 9680 1004 5099 1011 6154 1002 1014 1012 5585 1018 1024 6021 2258 2459 1010 2268 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: test-3
tokens: [CLS] toy ##fr ##ien ##d ( feat . w ##yn ##ter gordon ) [ continuous mix version ] david gu ##etta $ 1 . 29 2010 gum pro ##d licence exclusive par ##lo ##phone music france 21 - aug - 09 one love ( deluxe version ) dance , music 2 : 51 [SEP] sound of letting go ( feat . chris willis ) dance & electronic august 21 , 2009 david gu ##etta one love ( deluxe version ) $ 1 . 29 ( c ) 2014 swedish house mafia holdings ltd ( b ##vi ) under exclusive license to virgin records ltd 3 : 47 [SEP]
input_ids: 101 9121 19699 9013 2094 1006 8658 1012 1059 6038 3334 5146 1007 1031 7142 4666 2544 1033 2585 19739 16549 1002 1015 1012 2756 2230 16031 4013 2094 11172 7262 11968 4135 9864 2189 2605 2538 1011 15476 1011 5641 2028 2293 1006 15203 2544 1007 3153 1010 2189 1016 1024 4868 102 2614 1997 5599 2175 1006 8658 1012 3782 12688 1007 3153 1004 4816 2257 2538 1010 2268 2585 19739 16549 2028 2293 1006 15203 2544 1007 1002 1015 1012 2756 1006 1039 1007 2297 4467 2160 13897 9583 5183 1006 1038 5737 1007 2104 7262 6105 2000 6261 2636 5183 1017 1024 4700 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: [CLS] dangerous ( feat . sam martin ) [ robin sc ##hul ##z remix ] [ radio edit ] listen ( deluxe version ) dance , music , rock , house , electronic , french pop 2014 what a music ltd . under exclusive license to par ##lo ##phone / warner music france , under exclusive license to atlantic recording corporation for the united states . all rights reserved . 3 : 20 24 - nov - 14 david gu ##etta $ 1 . 29 [SEP] missing you ( feat . novel ; continuous mix version ) david gu ##etta one love ( deluxe version ) dance & electronic $ 1 . 29 ( c ) 2014 swedish house mafia holdings ltd ( b ##vi ) under exclusive license to virgin records ltd 4 : 59 august 21 , 2009 [SEP]
input_ids: 101 4795 1006 8658 1012 3520 3235 1007 1031 5863 8040 21886 2480 6136 1033 1031 2557 10086 1033 4952 1006 15203 2544 1007 3153 1010 2189 1010 2600 1010 2160 1010 4816 1010 2413 3769 2297 2054 1037 2189 5183 1012 2104 7262 6105 2000 11968 4135 9864 1013 6654 2189 2605 1010 2104 7262 6105 2000 4448 3405 3840 2005 1996 2142 2163 1012 2035 2916 9235 1012 1017 1024 2322 2484 1011 13292 1011 2403 2585 19739 16549 1002 1015 1012 2756 102 4394 2017 1006 8658 1012 3117 1025 7142 4666 2544 1007 2585 19739 16549 2028 2293 1006 15203 2544 1007 3153 1004 4816 1002 1015 1012 2756 1006 1039 1007 2297 4467 2160 13897 9583 5183 1006 1038 5737 1007 2104 7262 6105 2000 6261 2636 5183 1018 1024 5354 2257 2538 1010 2268 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 109
  Batch size = 16
  Max Sequence Length = 180
loaded and initialized evaluation examples 109
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.739127014364515
f1_score: 0.39705882352941174
simple_accuracy: 0.24770642201834864
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        82
           1       0.25      1.00      0.40        27

    accuracy                           0.25       109
   macro avg       0.12      0.50      0.20       109
weighted avg       0.06      0.25      0.10       109

[1;33mStart abt_buy DistilBERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=abt_buy
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=distilbert-base-uncased
argument: model_type=distilbert
argument: do_lower_case=True
argument: max_seq_length=265
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/abt_buy
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c
Model config {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": null,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "torchscript": false,
  "vocab_size": 30522
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/zye/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5
Weights of DistilBertForSequenceClassification not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
Weights from pretrained model not used in DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']
initialized distilbert-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 5743
*** Example ***
guid: train-0
tokens: [CLS] l ##g 24 ' lds ##48 ##21 ##w ##w semi integrated built in white dish ##wash ##er lds ##48 ##21 ##w ##h xl tall tub clean ##s up to 16 place settings at once adjustable upper rack lo ##de ##ci ##bel quiet operation sense ##cle ##an wash system 4 wash cycles with 3 spray arms multi - level water direction slim direct drive motor semi - integrated electronic control panel white finish [SEP] l ##g ld ##f ##6 ##9 ##20 ##bb fully integrated dish ##wash ##er [SEP]
input_ids: 101 1048 2290 2484 1005 17627 18139 17465 2860 2860 4100 6377 2328 1999 2317 9841 28556 2121 17627 18139 17465 2860 2232 28712 4206 14366 4550 2015 2039 2000 2385 2173 10906 2012 2320 26404 3356 14513 8840 3207 6895 8671 4251 3169 3168 14321 2319 9378 2291 1018 9378 12709 2007 1017 12509 2608 4800 1011 2504 2300 3257 11754 3622 3298 5013 4100 1011 6377 4816 2491 5997 2317 3926 102 1048 2290 25510 2546 2575 2683 11387 10322 3929 6377 9841 28556 2121 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: [CLS] spec ##k see ##th ##ru clear hard shell case for mac ##book air mba ##cl ##rse ##e thin and sleek protective case access to all ports 2 - piece snap on clear finish [SEP] spec ##k products see ##th ##ru case for apple 13 ' mac ##book mb ##13 - p ##nk - see - v ##2 plastic pink [SEP]
input_ids: 101 28699 2243 2156 2705 6820 3154 2524 5806 2553 2005 6097 8654 2250 15038 20464 22573 2063 4857 1998 21185 9474 2553 3229 2000 2035 8831 1016 1011 3538 10245 2006 3154 3926 102 28699 2243 3688 2156 2705 6820 2553 2005 6207 2410 1005 6097 8654 16914 17134 1011 1052 8950 1011 2156 1011 1058 2475 6081 5061 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: [CLS] den ##on blu - ray disc dvd / cd player dvd ##38 ##00 ##b ##dc ##i 10 - bit real ##ta hq ##v video processor 108 ##0 ##p / 24 ##fp ##s output and multi - cadence detection hd ##mi 1 . 3 a output with 36 - bit deep color support dual 32 - bit floating point ds ##p multi - layered construction with dual - layered top shields and triple - layered bottom suppress vibration hybrid ( s . v . h . ) load ##er black finish [SEP] den ##on dvd - 293 ##0 ##ci dvd player dvd ##29 ##30 ##ci dvd + r ##w , dvd - r ##w , cd - r ##w dvd video , dvd audio , sac ##d , video cd , picture cd , jp ##eg , w ##ma , pc ##m , hd ##cd , mp3 , mp ##eg - 1 , mp ##eg - 2 , mp ##eg - 4 , di ##v ##x playback 1 disc ( s ) progressive scan black [SEP]
input_ids: 101 7939 2239 14154 1011 4097 5860 4966 1013 3729 2447 4966 22025 8889 2497 16409 2072 2184 1011 2978 2613 2696 16260 2615 2678 13151 10715 2692 2361 1013 2484 22540 2015 6434 1998 4800 1011 23620 10788 10751 4328 1015 1012 1017 1037 6434 2007 4029 1011 2978 2784 3609 2490 7037 3590 1011 2978 8274 2391 16233 2361 4800 1011 21323 2810 2007 7037 1011 21323 2327 11824 1998 6420 1011 21323 3953 16081 17880 8893 1006 1055 1012 1058 1012 1044 1012 1007 7170 2121 2304 3926 102 7939 2239 4966 1011 26953 2692 6895 4966 2447 4966 24594 14142 6895 4966 1009 1054 2860 1010 4966 1011 1054 2860 1010 3729 1011 1054 2860 4966 2678 1010 4966 5746 1010 17266 2094 1010 2678 3729 1010 3861 3729 1010 16545 13910 1010 1059 2863 1010 7473 2213 1010 10751 19797 1010 23378 1010 6131 13910 1011 1015 1010 6131 13910 1011 1016 1010 6131 13910 1011 1018 1010 4487 2615 2595 18245 1015 5860 1006 1055 1007 6555 13594 2304 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: [CLS] pan ##as ##onic dec ##t 6 . 0 expand ##able digital cord ##less phone with all - digital answering system k ##xt ##g ##9 ##34 ##3 ##t 3 hands ##ets system up to 6 multi - hands ##et capability digital answering machine system ring ##er id call waiting caller id voice ##mail hold voice menu marker message mute clock alarm led lighting night mode call block speaker ##phone 11 days stand ##by 5 hours talk time black metallic finish [SEP] pan ##as ##onic k ##x - t ##g ##10 ##32 ##s dual hands ##et digital cord ##less phone 1 x phone line ( s ) heads ##et jack silver [SEP]
input_ids: 101 6090 3022 12356 11703 2102 1020 1012 1014 7818 3085 3617 11601 3238 3042 2007 2035 1011 3617 10739 2291 1047 18413 2290 2683 22022 2509 2102 1017 2398 8454 2291 2039 2000 1020 4800 1011 2398 3388 10673 3617 10739 3698 2291 3614 2121 8909 2655 3403 20587 8909 2376 21397 2907 2376 12183 12115 4471 20101 5119 8598 2419 7497 2305 5549 2655 3796 5882 9864 2340 2420 3233 3762 1019 2847 2831 2051 2304 12392 3926 102 6090 3022 12356 1047 2595 1011 1056 2290 10790 16703 2015 7037 2398 3388 3617 11601 3238 3042 1015 1060 3042 2240 1006 1055 1007 4641 3388 2990 3165 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: [CLS] sony silver mini ##d ##v handy ##cam cam ##cor ##der dc ##rh ##c ##52 680 ##k pixels image ##r carl ze ##iss var ##io - tessa ##r lens 40 ##x optical zoom and 2000 ##x digital zoom 2 . 5 ' touch panel lcd display super steady ##shot image stabilization super nights ##hot plus technology easy handy ##cam button fade ##r effects manual focus multi - language menu silver finish [SEP] sony mini ##d ##v head cleaner d ##v ##m ##12 ##cl ##d head cleaner [SEP]
input_ids: 101 8412 3165 7163 2094 2615 18801 28727 11503 27108 4063 5887 25032 2278 25746 23944 2243 27725 3746 2099 5529 27838 14643 13075 3695 1011 13167 2099 10014 2871 2595 9380 24095 1998 2456 2595 3617 24095 1016 1012 1019 1005 3543 5997 27662 4653 3565 6706 19040 3746 28715 3565 6385 12326 4606 2974 3733 18801 28727 6462 12985 2099 3896 6410 3579 4800 1011 2653 12183 3165 3926 102 8412 7163 2094 2615 2132 20133 1040 2615 2213 12521 20464 2094 2132 20133 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 5743
  Batch size = 16
  Max Sequence Length = 265
loaded 5743 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 1916
*** Example ***
guid: test-0
tokens: [CLS] sony pink cyber - shot 7 . 2 mega ##pi ##x ##el digital camera ds ##c ##w ##12 ##0 ##p 7 . 2 mega ##pi ##x ##el 4 ##x optical zoom 2 . 5 ' t ##ft lcd 15 mb internal memory face detection super steady ##shot image stabilization smile shutter mode smart zoom pink finish [SEP] olympus fe - 360 digital camera pink 226 ##54 ##0 8 mega ##pi ##x ##el 16 : 9 3 ##x optical zoom 4 ##x digital zoom 2 . 5 ' color lcd [SEP]
input_ids: 101 8412 5061 16941 1011 2915 1021 1012 1016 13164 8197 2595 2884 3617 4950 16233 2278 2860 12521 2692 2361 1021 1012 1016 13164 8197 2595 2884 1018 2595 9380 24095 1016 1012 1019 1005 1056 6199 27662 2321 16914 4722 3638 2227 10788 3565 6706 19040 3746 28715 2868 28180 5549 6047 24095 5061 3926 102 26742 10768 1011 9475 3617 4950 5061 21035 27009 2692 1022 13164 8197 2595 2884 2385 1024 1023 1017 2595 9380 24095 1018 2595 3617 24095 1016 1012 1019 1005 3609 27662 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: [CLS] l ##g 2 . 0 cu . ft . over - the - range white microwave oven l ##m ##v ##m ##20 ##85 ##w ##h warming lamp glide & spin sliding tray with turn ##table sensor cook feature 300 cf ##m exhaust system horizontal key ##pad elegant hidden vent wide ##view window halo ##gen cook ##top lighting white finish [SEP] may ##tag 2 . 0 cu . ft . over - the - range microwave oven [SEP]
input_ids: 101 1048 2290 1016 1012 1014 12731 1012 3027 1012 2058 1011 1996 1011 2846 2317 18302 17428 1048 2213 2615 2213 11387 27531 2860 2232 12959 10437 21096 1004 6714 8058 11851 2007 2735 10880 13617 5660 3444 3998 12935 2213 15095 2291 9876 3145 15455 11552 5023 18834 2898 8584 3332 17201 6914 5660 14399 7497 2317 3926 102 2089 15900 1016 1012 1014 12731 1012 3027 1012 2058 1011 1996 1011 2846 18302 17428 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: [CLS] pan ##as ##onic black 8 . 5 ' portable dvd player dvd ##ls ##8 ##3 8 . 5 ' free style wide screen lcd display 6 hour battery multi format playback dual head ##phone jack ##s di ##v ##x playback car dc adapt ##er included black finish [SEP] to ##shi ##ba sd - p ##7 ##1 ##s portable dvd player to ##shi ##ba sd - p ##7 ##1 ##s 7 ' portable dvd player [SEP]
input_ids: 101 6090 3022 12356 2304 1022 1012 1019 1005 12109 4966 2447 4966 4877 2620 2509 1022 1012 1019 1005 2489 2806 2898 3898 27662 4653 1020 3178 6046 4800 4289 18245 7037 2132 9864 2990 2015 4487 2615 2595 18245 2482 5887 15581 2121 2443 2304 3926 102 2000 6182 3676 17371 1011 1052 2581 2487 2015 12109 4966 2447 2000 6182 3676 17371 1011 1052 2581 2487 2015 1021 1005 12109 4966 2447 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: [CLS] sony bra ##via theater black micro system davis ##50 ##b 5 . 1 - channel surround sound golf ball - sized speakers compact design s - air digital wireless capability hd ##mi connectivity bra ##via sync digital cinema sound ( dc ##s ) technology s - master digital amplifier portable audio enhance ##r black finish [SEP] sony bra ##via da ##v - is ##50 / b home theater system dvd player , 5 . 1 speakers 1 disc ( s ) progressive scan 450 ##w rms do ##lby digital ex , do ##lby pro logic , do ##lby pro logic ii [SEP]
input_ids: 101 8412 11655 9035 4258 2304 12702 2291 4482 12376 2497 1019 1012 1015 1011 3149 15161 2614 5439 3608 1011 7451 7492 9233 2640 1055 1011 2250 3617 9949 10673 10751 4328 20831 11655 9035 26351 3617 5988 2614 1006 5887 2015 1007 2974 1055 1011 3040 3617 22686 12109 5746 11598 2099 2304 3926 102 8412 11655 9035 4830 2615 1011 2003 12376 1013 1038 2188 4258 2291 4966 2447 1010 1019 1012 1015 7492 1015 5860 1006 1055 1007 6555 13594 10332 2860 29311 2079 14510 3617 4654 1010 2079 14510 4013 7961 1010 2079 14510 4013 7961 2462 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: test-4
tokens: [CLS] pan ##as ##onic dec ##t 6 . 0 expand ##able digital cord ##less phone with all - digital answering system k ##xt ##g ##9 ##34 ##4 ##t 4 hands ##ets system up to 6 multi - hands ##et capability digital answering machine system ring ##er id call waiting caller id voice ##mail hold voice menu marker message mute clock alarm led lighting night mode call block speaker ##phone 11 days stand ##by 5 hours talk time black metallic finish [SEP] pan ##as ##onic k ##x - t ##g ##9 ##34 ##2 ##t cord ##less phone 1 x phone line ( s ) black , metallic [SEP]
input_ids: 101 6090 3022 12356 11703 2102 1020 1012 1014 7818 3085 3617 11601 3238 3042 2007 2035 1011 3617 10739 2291 1047 18413 2290 2683 22022 2549 2102 1018 2398 8454 2291 2039 2000 1020 4800 1011 2398 3388 10673 3617 10739 3698 2291 3614 2121 8909 2655 3403 20587 8909 2376 21397 2907 2376 12183 12115 4471 20101 5119 8598 2419 7497 2305 5549 2655 3796 5882 9864 2340 2420 3233 3762 1019 2847 2831 2051 2304 12392 3926 102 6090 3022 12356 1047 2595 1011 1056 2290 2683 22022 2475 2102 11601 3238 3042 1015 1060 3042 2240 1006 1055 1007 2304 1010 12392 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 1916
  Batch size = 16
  Max Sequence Length = 265
loaded and initialized evaluation examples 1916
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7572581922014554
f1_score: 0.1941564561734213
simple_accuracy: 0.10751565762004175
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1710
           1       0.11      1.00      0.19       206

    accuracy                           0.11      1916
   macro avg       0.05      0.50      0.10      1916
weighted avg       0.01      0.11      0.02      1916

[1;33mStart dirty_walmart_amazon DistilBERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_walmart_amazon
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=distilbert-base-uncased
argument: model_type=distilbert
argument: do_lower_case=True
argument: max_seq_length=150
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_walmart_amazon
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c
Model config {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": null,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "torchscript": false,
  "vocab_size": 30522
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/zye/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5
Weights of DistilBertForSequenceClassification not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
Weights from pretrained model not used in DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']
initialized distilbert-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 6144
*** Example ***
guid: train-0
tokens: [CLS] elite screens ci ##ne ##w ##hit ##e cinema ##23 ##5 series fixed frame wide screen - 85 diagonal electronics - general elite screens r ##85 ##w ##h ##1 - wide 40 ##9 . 0 [SEP] ci ##ne ##gra ##y e ##z ##frame series fixed frame screen - 150 diagonal 87 ##9 . 0 projection screens elite [SEP]
input_ids: 101 7069 12117 25022 2638 2860 16584 2063 5988 21926 2629 2186 4964 4853 2898 3898 1011 5594 19754 8139 1011 2236 7069 12117 1054 27531 2860 2232 2487 1011 2898 2871 2683 1012 1014 102 25022 2638 17643 2100 1041 2480 15643 2186 4964 4853 3898 1011 5018 19754 6584 2683 1012 1014 13996 12117 7069 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: [CLS] san diego padres iphone 4 case silicon ##e cover electronics - general tribe ##ca f ##va ##39 ##59 24 . 99 [SEP] georgia bulldogs iphone 4 case silicon ##e cover tribe ##ca 17 . 99 computers accessories [SEP]
input_ids: 101 2624 5277 21577 18059 1018 2553 13773 2063 3104 8139 1011 2236 5917 3540 1042 3567 23499 28154 2484 1012 5585 102 4108 15120 18059 1018 2553 13773 2063 3104 5917 3540 2459 1012 5585 7588 16611 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: [CLS] inn ##over ##a d ##30 ##10 black compatible high - yield tone ##r print cartridge station ##ery & office machinery d ##30 ##10 inn ##over ##a 68 . 35 [SEP] premium compatible hp 11 ##x tone ##r cartridge hp q ##65 ##11 ##x . black print cartridge high yield hp 1200 ##0 pages . . compatible ink ##jet printer ink hp - q ##65 ##11 ##x 28 . 92 [SEP]
input_ids: 101 7601 7840 2050 1040 14142 10790 2304 11892 2152 1011 10750 4309 2099 6140 15110 2276 7301 1004 2436 10394 1040 14142 10790 7601 7840 2050 6273 1012 3486 102 12882 11892 6522 2340 2595 4309 2099 15110 6522 1053 26187 14526 2595 1012 2304 6140 15110 2152 10750 6522 14840 2692 5530 1012 1012 11892 10710 15759 15041 10710 6522 1011 1053 26187 14526 2595 2654 1012 6227 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: [CLS] da - lit ##e da - pl ##ex base rear projection screen - 57 3 4 x 77 video format da - lit ##e 260 ##8 . 99 electronics - general 275 ##28 [SEP] da - lit ##e 275 ##14 da - pl ##ex un ##frame ##d rear projection screen - 108 x 144 video format projection screens da - lit ##e [SEP]
input_ids: 101 4830 1011 5507 2063 4830 1011 20228 10288 2918 4373 13996 3898 1011 5401 1017 1018 1060 6255 2678 4289 4830 1011 5507 2063 13539 2620 1012 5585 8139 1011 2236 17528 22407 102 4830 1011 5507 2063 17528 16932 4830 1011 20228 10288 4895 15643 2094 4373 13996 3898 1011 10715 1060 14748 2678 4289 13996 12117 4830 1011 5507 2063 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-4
tokens: [CLS] pc treasures wireless optical mouse 2 . 4 ghz purple 07 ##22 ##7 mice pc treasures 17 . 82 [SEP] inland pro 2 . 4 ghz wireless optical mouse 07 ##44 ##1 12 . 98 mice inland [SEP]
input_ids: 101 7473 17605 9949 9380 8000 1016 1012 1018 29066 6379 5718 19317 2581 12328 7473 17605 2459 1012 6445 102 9514 4013 1016 1012 1018 29066 9949 9380 8000 5718 22932 2487 2260 1012 5818 12328 9514 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-4102' was too long (tokens_a:65, tokens_b:89). Max_seq_length is 147, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 6144
  Batch size = 16
  Max Sequence Length = 150
loaded 6144 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 2049
*** Example ***
guid: test-0
tokens: [CLS] sony 16 ##gb class 4 sd memory card sony 0 . 0 usb drives sf ##16 ##n ##4 / tq ##p [SEP] p ##ny 4 ##gb class 4 navy sd card car audio video p ##ny p - sd ##hc ##4 ##g ##4 - e ##f / navy 11 . 18 [SEP]
input_ids: 101 8412 2385 18259 2465 1018 17371 3638 4003 8412 1014 1012 1014 18833 9297 16420 16048 2078 2549 1013 28816 2361 102 1052 4890 1018 18259 2465 1018 3212 17371 4003 2482 5746 2678 1052 4890 1052 1011 17371 16257 2549 2290 2549 1011 1041 2546 1013 3212 2340 1012 2324 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: [CLS] z ##ota ##c ge ##force gt ##43 ##0 1 ##gb dd ##r ##3 pc ##i - express 2 . 0 graphics card z ##ota ##c electronics - general z ##t - 406 ##0 ##4 - 10 ##l 88 . 88 [SEP] ev ##ga ge ##force gt ##s ##45 ##0 super ##cl ##ock ##ed 1 gb g ##dd ##r ##5 pc ##i - express 2 . 0 graphics card 01 ##g - p ##3 - 145 ##2 - tr graphics cards ev ##ga 01 ##g - p ##3 - 145 ##2 - tr 119 . 88 [SEP]
input_ids: 101 1062 17287 2278 16216 14821 14181 23777 2692 1015 18259 20315 2099 2509 7473 2072 1011 4671 1016 1012 1014 8389 4003 1062 17287 2278 8139 1011 2236 1062 2102 1011 27433 2692 2549 1011 2184 2140 6070 1012 6070 102 23408 3654 16216 14821 14181 2015 19961 2692 3565 20464 7432 2098 1015 16351 1043 14141 2099 2629 7473 2072 1011 4671 1016 1012 1014 8389 4003 5890 2290 1011 1052 2509 1011 13741 2475 1011 19817 8389 5329 23408 3654 5890 2290 1011 1052 2509 1011 13741 2475 1011 19817 13285 1012 6070 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: [CLS] da - lit ##e high power model b manual screen with cs ##r - 84 x 84 av format electronics - general da - lit ##e 85 ##30 ##3 37 ##2 . 99 [SEP] da - lit ##e advantage manual with cs ##r - projection screen - 133 in - 16 9 - high power da - lit ##e 90 ##4 . 95 home audio theater [SEP]
input_ids: 101 4830 1011 5507 2063 2152 2373 2944 1038 6410 3898 2007 20116 2099 1011 6391 1060 6391 20704 4289 8139 1011 2236 4830 1011 5507 2063 5594 14142 2509 4261 2475 1012 5585 102 4830 1011 5507 2063 5056 6410 2007 20116 2099 1011 13996 3898 1011 14506 1999 1011 2385 1023 1011 2152 2373 4830 1011 5507 2063 3938 2549 1012 5345 2188 5746 4258 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: [CLS] da - lit ##e hc cinema vision tension ##ed advantage electro ##l - av format 8 x 8 diagonal electronics - general da - lit ##e 89 ##9 ##39 259 ##5 . 0 [SEP] hc da - mat tension ##ed advantage electro ##l - av format 50 x 50 da - lit ##e projection screens [SEP]
input_ids: 101 4830 1011 5507 2063 16731 5988 4432 6980 2098 5056 16175 2140 1011 20704 4289 1022 1060 1022 19754 8139 1011 2236 4830 1011 5507 2063 6486 2683 23499 25191 2629 1012 1014 102 16731 4830 1011 13523 6980 2098 5056 16175 2140 1011 20704 4289 2753 1060 2753 4830 1011 5507 2063 13996 12117 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: [CLS] verb ##ati ##m 4 ##gb tu ##ff - n - tiny usb 2 . 0 flash drive green usb drives verb ##ati ##m 11 . 98 [SEP] verb ##ati ##m clip - it 4 gb usb 2 . 0 flash drive 97 ##55 ##6 green usb flash drives 10 . 98 verb ##ati ##m 97 ##55 ##6 [SEP]
input_ids: 101 12034 10450 2213 1018 18259 10722 4246 1011 1050 1011 4714 18833 1016 1012 1014 5956 3298 2665 18833 9297 12034 10450 2213 2340 1012 5818 102 12034 10450 2213 12528 1011 2009 1018 16351 18833 1016 1012 1014 5956 3298 5989 24087 2575 2665 18833 5956 9297 2184 1012 5818 12034 10450 2213 5989 24087 2575 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 2049
  Batch size = 16
  Max Sequence Length = 150
loaded and initialized evaluation examples 2049
***** Run training *****
***** Eval results after epoch -1 *****
eval_loss: 0.7562999050746593
f1_score: 0.17216770740410348
simple_accuracy: 0.09419228892142509
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1856
           1       0.09      1.00      0.17       193

    accuracy                           0.09      2049
   macro avg       0.05      0.50      0.09      2049
weighted avg       0.01      0.09      0.02      2049

***** Eval results after epoch 0 *****
eval_loss: 0.1633667478467836
f1_score: 0.6753926701570682
simple_accuracy: 0.9394826744753538
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      1856
           1       0.68      0.67      0.68       193

    accuracy                           0.94      2049
   macro avg       0.82      0.82      0.82      2049
weighted avg       0.94      0.94      0.94      2049

***** Eval results after epoch 1 *****
eval_loss: 0.1784905305063684
f1_score: 0.7247191011235956
simple_accuracy: 0.9521717911176184
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1856
           1       0.79      0.67      0.72       193

    accuracy                           0.95      2049
   macro avg       0.88      0.83      0.85      2049
weighted avg       0.95      0.95      0.95      2049

***** Eval results after epoch 2 *****
eval_loss: 0.19449809133237617
f1_score: 0.7298050139275766
simple_accuracy: 0.9526598340653978
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1856
           1       0.79      0.68      0.73       193

    accuracy                           0.95      2049
   macro avg       0.88      0.83      0.85      2049
weighted avg       0.95      0.95      0.95      2049

[1;33mStart dirty_dblp_acm DistilBERT [0m
*** parsed configuration from command line and combine with constants ***
argument: data_dir=dirty_dblp_acm
argument: data_processor=DeepMatcherProcessor
argument: model_name_or_path=distilbert-base-uncased
argument: model_type=distilbert
argument: do_lower_case=True
argument: max_seq_length=180
argument: train_batch_size=16
argument: eval_batch_size=16
argument: num_epochs=15.0
argument: save_model_after_epoch=False
argument: learning_rate=2e-05
argument: adam_eps=1e-08
argument: warmup_steps=0
argument: max_grad_norm=1.0
argument: weight_decay=0.0
argument: seed=22
argument: data_path=data/dirty_dblp_acm
argument: model_output_dir=experiments
We use the device: 'cpu' and 0 gpu's. Important: distributed and 16-bits training is currently not implemented! 
training with 2 labels: ['0', '1']
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /home/zye/.cache/torch/pytorch_transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c
Model config {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": null,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "torchscript": false,
  "vocab_size": 30522
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/zye/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /home/zye/.cache/torch/pytorch_transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5
Weights of DistilBertForSequenceClassification not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
Weights from pretrained model not used in DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']
initialized distilbert-model
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.TRAINING] *****
Writing example 0 of 7417
*** Example ***
guid: train-0
tokens: [CLS] web ca ##ching for database applications with oracle web cache jordan parker , jesse anton , zheng zen ##g , lawrence jacobs , tie z ##hong , xiang liu si ##gm ##od conference 2002 . 0 [SEP] form - based proxy ca ##ching for database - backed web sites very large data bases qi ##ong lu ##o , jeffrey f . na ##ught ##on 2001 . 0 [SEP]
input_ids: 101 4773 6187 8450 2005 7809 5097 2007 14721 4773 17053 5207 6262 1010 7627 9865 1010 20985 16729 2290 1010 5623 12988 1010 5495 1062 19991 1010 27735 8607 9033 21693 7716 3034 2526 1012 1014 102 2433 1011 2241 24540 6187 8450 2005 7809 1011 6153 4773 4573 2200 2312 2951 7888 18816 5063 11320 2080 1010 10799 1042 1012 6583 18533 2239 2541 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-1
tokens: [CLS] oracle industrial exhibit 1998 amy po ##gue v ##ld ##b [SEP] object ##ivity industrial exhibit object ##ivity very large data bases 1998 . 0 [SEP]
input_ids: 101 14721 3919 8327 2687 6864 13433 9077 1058 6392 2497 102 4874 7730 3919 8327 4874 7730 2200 2312 2951 7888 2687 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-2
tokens: [CLS] extract ##ing large - scale knowledge bases from the web andrew tom ##kins , pr ##ab ##hak ##ar rag ##havan , ravi kumar , sri ##dhar raja ##go ##pala ##n v ##ld ##b 1999 . 0 [SEP] ama ##lga ##mat ##ing knowledge bases v . s . sub ##rah ##mania ##n ac ##m transactions on database systems ( tod ##s ) 1994 . 0 [SEP]
input_ids: 101 14817 2075 2312 1011 4094 3716 7888 2013 1996 4773 4080 3419 14322 1010 10975 7875 20459 2906 17768 24652 1010 16806 9600 1010 5185 25632 10164 3995 19636 2078 1058 6392 2497 2639 1012 1014 102 25933 27887 18900 2075 3716 7888 1058 1012 1055 1012 4942 10404 27010 2078 9353 2213 11817 2006 7809 3001 1006 28681 2015 1007 2807 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: train-3
tokens: [CLS] efficient optimistic concurrency control using loosely synchronized clocks si ##gm ##od conference barbara li ##sko ##v , at ##ul ad ##ya , robert gr ##uber , um ##esh ma ##hes ##hwa ##ri 1995 . 0 [SEP] efficient optimistic concurrency control using loosely synchronized clocks at ##ul ad ##ya , robert gr ##uber , barbara li ##sko ##v , um ##esh ma ##hes ##hwa ##ri international conference on management of data 1995 . 0 [SEP]
input_ids: 101 8114 21931 24154 2491 2478 11853 25549 20940 9033 21693 7716 3034 6437 5622 21590 2615 1010 2012 5313 4748 3148 1010 2728 24665 21436 1010 8529 9953 5003 15689 18663 3089 2786 1012 1014 102 8114 21931 24154 2491 2478 11853 25549 20940 2012 5313 4748 3148 1010 2728 24665 21436 1010 6437 5622 21590 2615 1010 8529 9953 5003 15689 18663 3089 2248 3034 2006 2968 1997 2951 2786 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 1 (id = 1)
*** Example ***
guid: train-4
tokens: [CLS] ode ##fs : a file system interface to an object - oriented database nara ##in h . ge ##hani , william d . room ##e , h . v . ja ##ga ##dis ##h v ##ld ##b 1994 . 0 [SEP] un ##is ##q ##l / x unified relational and object - oriented database system won kim 1994 international conference on management of data [SEP]
input_ids: 101 24040 10343 1024 1037 5371 2291 8278 2000 2019 4874 1011 8048 7809 27544 2378 1044 1012 16216 23573 1010 2520 1040 1012 2282 2063 1010 1044 1012 1058 1012 14855 3654 10521 2232 1058 6392 2497 2807 1012 1014 102 4895 2483 4160 2140 1013 1060 10562 28771 1998 4874 1011 8048 7809 2291 2180 5035 2807 2248 3034 2006 2968 1997 2951 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'train-2770' was too long (tokens_a:118, tokens_b:118). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'train-3897' was too long (tokens_a:121, tokens_b:121). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'train-4613' was too long (tokens_a:96, tokens_b:97). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'train-5238' was too long (tokens_a:116, tokens_b:97). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'train-6632' was too long (tokens_a:109, tokens_b:114). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'train-6755' was too long (tokens_a:94, tokens_b:102). Max_seq_length is 177, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.TRAINING] *****
  Num examples = 7417
  Batch size = 16
  Max Sequence Length = 180
loaded 7417 training examples
Built optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
***** Convert Data to Features (Word-Piece Tokenizing) [DataType.EVALUATION] *****
Writing example 0 of 2473
*** Example ***
guid: test-0
tokens: [CLS] secure transaction processing in firm real - time database systems bin ##to george , jaya ##nt r . hari ##tsa si ##gm ##od conference 1997 . 0 [SEP] secure buffer ##ing in firm real - time database systems 2000 bin ##to george , jaya ##nt r . hari ##tsa the v ##ld ##b journal - - the international journal on very large data bases [SEP]
input_ids: 101 5851 12598 6364 1999 3813 2613 1011 2051 7809 3001 8026 3406 2577 1010 24120 3372 1054 1012 21291 27110 9033 21693 7716 3034 2722 1012 1014 102 5851 17698 2075 1999 3813 2613 1011 2051 7809 3001 2456 8026 3406 2577 1010 24120 3372 1054 1012 21291 27110 1996 1058 6392 2497 3485 1011 1011 1996 2248 3485 2006 2200 2312 2951 7888 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-1
tokens: [CLS] cluster ##ing validity checking methods : part ii mic ##hal ##is va ##zi ##rg ##ian ##nis , maria hal ##ki ##di , yan ##nis bat ##ista ##kis si ##gm ##od record 2002 . 0 [SEP] cluster validity methods : part i 2002 maria hal ##ki ##di , yan ##nis bat ##ista ##kis , mic ##hal ##is va ##zi ##rg ##ian ##nis ac ##m si ##gm ##od record [SEP]
input_ids: 101 9324 2075 16406 9361 4725 1024 2112 2462 23025 8865 2483 12436 5831 10623 2937 8977 1010 3814 11085 3211 4305 1010 13619 8977 7151 11921 14270 9033 21693 7716 2501 2526 1012 1014 102 9324 16406 4725 1024 2112 1045 2526 3814 11085 3211 4305 1010 13619 8977 7151 11921 14270 1010 23025 8865 2483 12436 5831 10623 2937 8977 9353 2213 9033 21693 7716 2501 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-2
tokens: [CLS] a query language and optimization techniques for un ##st ##ructured data ge ##rd g . hill ##eb ##rand , peter bun ##eman , susan b . davidson , dan su ##ci ##u si ##gm ##od conference 1996 . 0 [SEP] fundamental techniques for order optimization david sim ##men , eugene she ##kit ##a , timothy mal ##ke ##mus international conference on management of data 1996 . 0 [SEP]
input_ids: 101 1037 23032 2653 1998 20600 5461 2005 4895 3367 26134 2951 16216 4103 1043 1012 2940 15878 13033 1010 2848 21122 16704 1010 6294 1038 1012 12017 1010 4907 10514 6895 2226 9033 21693 7716 3034 2727 1012 1014 102 8050 5461 2005 2344 20600 2585 21934 3549 1010 8207 2016 23615 2050 1010 10805 15451 3489 7606 2248 3034 2006 2968 1997 2951 2727 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-3
tokens: [CLS] structures for manipulating proposed updates in object - oriented databases richard hull , mohammed ru ##pa ##wall ##a , michael doherty 1996 si ##gm ##od conference [SEP] observations on the o ##dm ##g - 93 proposal for an object - oriented database language won kim ac ##m si ##gm ##od record 1994 . 0 [SEP]
input_ids: 101 5090 2005 26242 3818 14409 1999 4874 1011 8048 17881 2957 6738 1010 12619 21766 4502 9628 2050 1010 2745 23798 2727 9033 21693 7716 3034 102 9420 2006 1996 1051 22117 2290 1011 6109 6378 2005 2019 4874 1011 8048 7809 2653 2180 5035 9353 2213 9033 21693 7716 2501 2807 1012 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
*** Example ***
guid: test-4
tokens: [CLS] integrating a structured - text retrieval system with an object - oriented database system jurgen anne ##vel ##ink , tak w . yan v ##ld ##b 1994 . 0 [SEP] index nesting - an efficient approach to index ##ing in object - oriented databases ben ##g chin o ##oi , jia ##wei han , hong ##jun lu , kia ##n lee tan the v ##ld ##b journal - - the international journal on very large data bases 1996 [SEP]
input_ids: 101 22380 1037 14336 1011 3793 26384 2291 2007 2019 4874 1011 8048 7809 2291 23171 4776 15985 19839 1010 27006 1059 1012 13619 1058 6392 2497 2807 1012 1014 102 5950 21016 1011 2019 8114 3921 2000 5950 2075 1999 4874 1011 8048 17881 3841 2290 5413 1051 10448 1010 25871 19845 7658 1010 4291 19792 11320 1010 27005 2078 3389 9092 1996 1058 6392 2497 3485 1011 1011 1996 2248 3485 2006 2200 2312 2951 7888 2727 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
label: 0 (id = 0)
Sample with ID 'test-1626' was too long (tokens_a:111, tokens_b:116). Max_seq_length is 177, so we reduce it in a smart way
Sample with ID 'test-2398' was too long (tokens_a:99, tokens_b:105). Max_seq_length is 177, so we reduce it in a smart way
***** Build PyTorch DataLoader with extracted features [DataType.EVALUATION] *****
  Num examples = 2473
  Batch size = 16
  Max Sequence Length = 180
loaded and initialized evaluation examples 2473
***** Run training *****
